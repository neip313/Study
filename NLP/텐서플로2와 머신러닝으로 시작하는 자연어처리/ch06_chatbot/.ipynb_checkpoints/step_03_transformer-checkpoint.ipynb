{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geWXPvDBZ0pn"
   },
   "source": [
    "## 데이터셋 소개\n",
    "- 한국어 챗봇 데이터는 거의 없다. \n",
    "  + 다행히, 한글로도 챗봇을 만들수 있도록 `Chatbot_data_for_Korean v1.0` 데이터셋이다. \n",
    "- 총 11,876개의 데이터로 구성돼 있다. \n",
    "  + 각 데이터는 질문과 그에 대한 대답, 그리고 주제에 대한 라벨값을 가진다. \n",
    "    * 0은 일상 대화, 1은 긍정, 2는 부정의 주제를 의미한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mxmlN1EgEGN"
   },
   "source": [
    "## 데이터 분석\n",
    "- 챗봇 데이터를 분석해보자. \n",
    "- 데이터 출처: https://github.com/songys/Chatbot_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bcv5EKRyjTck"
   },
   "source": [
    "### 구글 코랩과 구글 드라이브 연동\n",
    "- 우선 데이터가 있는 폴더와 연동한다. \n",
    "> Note: 런타임을 GPU로 바꾸는 것을 잊지 않는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20468,
     "status": "ok",
     "timestamp": 1609134822628,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "1wwqlWe7ZvR2",
    "outputId": "4014b24f-3c7d-41cd-803c-133392d925c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive\n",
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/Colab Notebooks/강림직업전문학교/프로젝트/NLP_자연어처리/ch06_챗봇_만들기/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive # 패키지 불러오기 \n",
    "from os.path import join  \n",
    "\n",
    "ROOT = \"/content/drive\"     # 드라이브 기본 경로\n",
    "print(ROOT)                 # print content of ROOT (Optional)\n",
    "drive.mount(ROOT)           # 드라이브 기본 경로 Mount\n",
    "\n",
    "MY_GOOGLE_DRIVE_PATH = 'My Drive/Colab Notebooks/강림직업전문학교/프로젝트/NLP_자연어처리/ch06_챗봇_만들기/' # 프로젝트 경로\n",
    "PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH) # 프로젝트 경로\n",
    "print(PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1457,
     "status": "ok",
     "timestamp": 1609134871938,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "c2nDwL2UjOWQ",
    "outputId": "5cf45b2e-0776-4d3e-e2a1-392f1a719c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/강림직업전문학교/프로젝트/NLP_자연어처리/ch06_챗봇_만들기\n"
     ]
    }
   ],
   "source": [
    "%cd \"{PROJECT_PATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jx14uFbik8IB"
   },
   "source": [
    "### 데이터 불러오기 및 확인\n",
    "- Pandas 라이브러리를 활용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 1334,
     "status": "ok",
     "timestamp": 1609134878574,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "WxnhdWyblCtI",
    "outputId": "f4fe24db-058d-4226-ed80-34b1f5a8b7c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "DATA_IN_PATH = \"./data_in/\"\n",
    "data = pd.read_csv(DATA_IN_PATH + './ChatBotData.csv', encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-baWuRTXnU3N"
   },
   "source": [
    "- 결과에 응답 데이터를 보면, 주로 권유의 문자열이 많이 나오는 것을 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKBhT3Chopmm"
   },
   "source": [
    "### 한글 형태소 설치\n",
    "- 다음 코드로 형태소를 설치하도록 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32637,
     "status": "ok",
     "timestamp": 1609134909891,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "ktrUGCf-o4G2",
    "outputId": "3d0de054-4dbd-48d4-8c6a-fe981e3dfd0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [Working]\r",
      "            \r",
      "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
      "Get:13 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [41.5 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,703 kB]\n",
      "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [872 kB]\n",
      "Fetched 2,889 kB in 3s (936 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
      "g++ set to manually installed.\n",
      "The following additional packages will be installed:\n",
      "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
      "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
      "  openjdk-8-jre-headless x11-utils\n",
      "Suggested packages:\n",
      "  gvfs openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin libnss-mdns\n",
      "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
      "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
      "The following NEW packages will be installed:\n",
      "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
      "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n",
      "  openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
      "0 upgraded, 15 newly installed, 0 to remove and 17 not upgraded.\n",
      "Need to get 43.4 MB of archives.\n",
      "After this operation, 163 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u275-b01-0ubuntu1~18.04 [28.2 MB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u275-b01-0ubuntu1~18.04 [69.7 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u275-b01-0ubuntu1~18.04 [8,269 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u275-b01-0ubuntu1~18.04 [1,600 kB]\n",
      "Fetched 43.4 MB in 3s (12.8 MB/s)\n",
      "Selecting previously unselected package libxxf86dga1:amd64.\n",
      "(Reading database ... 145480 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
      "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../01-fonts-dejavu-core_2.37-1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.37-1) ...\n",
      "Selecting previously unselected package fonts-dejavu-extra.\n",
      "Preparing to unpack .../02-fonts-dejavu-extra_2.37-1_all.deb ...\n",
      "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
      "Selecting previously unselected package x11-utils.\n",
      "Preparing to unpack .../03-x11-utils_7.7+3build1_amd64.deb ...\n",
      "Unpacking x11-utils (7.7+3build1) ...\n",
      "Selecting previously unselected package libatk-wrapper-java.\n",
      "Preparing to unpack .../04-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
      "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
      "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
      "Preparing to unpack .../05-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
      "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
      "Selecting previously unselected package libgtk2.0-common.\n",
      "Preparing to unpack .../06-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
      "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgtk2.0-0:amd64.\n",
      "Preparing to unpack .../07-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgail18:amd64.\n",
      "Preparing to unpack .../08-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgail-common:amd64.\n",
      "Preparing to unpack .../09-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgtk2.0-bin.\n",
      "Preparing to unpack .../10-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
      "Preparing to unpack .../11-openjdk-8-jre-headless_8u275-b01-0ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jre-headless:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "Selecting previously unselected package openjdk-8-jre:amd64.\n",
      "Preparing to unpack .../12-openjdk-8-jre_8u275-b01-0ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jre:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
      "Preparing to unpack .../13-openjdk-8-jdk-headless_8u275-b01-0ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jdk-headless:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
      "Preparing to unpack .../14-openjdk-8-jdk_8u275-b01-0ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jdk:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
      "Setting up fonts-dejavu-core (2.37-1) ...\n",
      "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
      "Setting up fonts-dejavu-extra (2.37-1) ...\n",
      "Setting up openjdk-8-jre-headless:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
      "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up openjdk-8-jdk-headless:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
      "Setting up x11-utils (7.7+3build1) ...\n",
      "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
      "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
      "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
      "Setting up openjdk-8-jre:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
      "Setting up openjdk-8-jdk:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
      "Processing triggers for mime-support (3.60ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n",
      "Collecting konlpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
      "\u001b[K     |████████████████████████████████| 19.4MB 115kB/s \n",
      "\u001b[?25hCollecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.4)\n",
      "Collecting tweepy>=3.7.0\n",
      "  Downloading https://files.pythonhosted.org/packages/67/c3/6bed87f3b1e5ed2f34bd58bf7978e308c86e255193916be76e5a5ce5dfca/tweepy-3.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
      "Collecting beautifulsoup4==4.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 14.9MB/s \n",
      "\u001b[?25hCollecting JPype1>=0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/21/9e2c0dbf9df856e6392a1aec1d18006c60b175aa4e31d351e8278a8a63c0/JPype1-1.2.0-cp36-cp36m-manylinux2010_x86_64.whl (453kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 58.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Installing collected packages: colorama, tweepy, beautifulsoup4, JPype1, konlpy\n",
      "  Found existing installation: tweepy 3.6.0\n",
      "    Uninstalling tweepy-3.6.0:\n",
      "      Successfully uninstalled tweepy-3.6.0\n",
      "  Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "Successfully installed JPype1-1.2.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.10.0\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install g++ openjdk-8-jdk \n",
    "!pip3 install --target=$my_path konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCdbS2j9rrnE"
   },
   "source": [
    "## 트랜스포머 모델\n",
    "- 트랜스포머란 구글이 2017년에 소개한 논문인 \"Attention is all you need\"에 나온 모델이다. \n",
    "- 기존의 시퀀스 투 시퀀스의 인코더 디코더 구조를 가지고 있지만, 합성곱 신경망(CNN), 순환 신경망(RNN)을 기반으로 구성된 기존 모델과 다르게 단순히 어텐션 구조만으로 전체 모델을 만들어 어텐션 기법의 중요성을 강조함\n",
    "- 어텐션이란 무엇인가?\n",
    "  + 자세한 설명은 [Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/) 참조 하시기를 바랍니다. \n",
    "  + 간단하게 설명하면, 디코더에서 예측하려는 단어를 출력할 때마다 인코더의 전체 문장을 한번 더 참고하려고 한다는 점이다. 이 때, 전체 문장들이 응축되어 모여 있는 곳이 `Context Vector`라고 보면 된다. \n",
    "- 트랜스포머는 `seq2seq` 모델의 `attention`에 집중을 한 모델로 보면 된다. \n",
    "- 기본적으로 트랜스포머 모델은 앞서 순환 신경망 기반의 시퀀스 투 시퀀스 모델과 같이 인코더와 디코더로 구성되며 인코더에서 입력한 문장에 대한 정보와 디코더에 입력한 문장 정보를 조합해서 디코더 문장 다음에 나올 단어에 대해 생성하는 방법이다. \n",
    "- 시퀀스 투 시퀀스와 다른 점은 순환 신경망을 활용하지 않고 셀프 어텐션 기법을 사용해 문장에 대한 정보를 추출한다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7K0zh2d2vPqC"
   },
   "source": [
    "## 셀프 어텐션\n",
    "- 셀프 어텐션(`Self-Attention`)이란 문장에서 각 단어끼리 얼마나 관계가 있는지를 계산해서 반영하는 방법\n",
    "- 즉, 셀프 어텐션을 이용하면 문장 안에서 단어들 간의 관계를 측정할 수 있다. \n",
    "  + 이 값을 어텐션 스코어(`attention score`)라고 부른다. \n",
    "  + \"딥러닝\"을 기반으로 한 예시 문장을 들면 아래와 같다. \n",
    "> 딥러닝(=0.25) 텐서플로우(=0.25) 자연어(=0.25) 처리(=0.15) 아주(=0.05) 좋아요(=0.05)\n",
    "\n",
    "- 이 어텐션 스코어 값을 하나의 테이블로 만든 것을 어텐션 맵이라고 부른다. \n",
    "- 이제 이 어텐션 맵을 활용해 문장을 서로의 관계를 반영한 값으로 바꿔야 한다. \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrDdKd8pxZtK"
   },
   "source": [
    "### 어텐션 스코어 구하는 방법\n",
    "- 어텐션 구하는 기법은 우선 의미 정보를 벡터로 표현해서 유사도 점수를 계산한다. \n",
    "  + 이 때의 유사도를 구하는 방법은 크게 맨하탄 거리와 같은 유사도 공식을 활용해 구하는 방법과, Dense 층을 거쳐 나온 값을 활용하는 방법이 있다. \n",
    "  + 트랜스포머 모델에서는 단어 벡터끼리 내적 연산을 함으로써 어텐션 스코어를 구한다. \n",
    "- 어텐션 스코어를 구한 후, 어텐션 스코어가 모여 있는 어텐션 맵에 소프트맥스 함수를 적용한다. \n",
    "  + 어텐션 맵이 특정 단어에 대한 다른 단어와의 연관도 값의 확률로 나타난다. 이제 이 값을 해당 단어에 반영해야 한다. 스코어가 큰 경우 해당 단어와 관련이 높은 단어이므로 큰 값을 가져야 한다. \n",
    "- 이 확률값과 기존의 각 단어 벡터를 가중합한다. 가중합이란, 각 확률값과 각 단어 벡터를 곱한 후 더하는 연산이다. 이렇게 구한 값을 해당 단어에 대한 벡터값으로 사용하게 된다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAt7SMB30s9S"
   },
   "source": [
    "## 모델 구현을 위한 사전 준비\n",
    "- 이제 본격적으로 모델 구현을 진행한다. \n",
    "- 모델 구현의 경우 큰 틀은 앞서 구현한 RNN 기반 시퀀스 투 시퀀스 모델과 거의 유사하다. \n",
    "- 모델의 경우 큰 틀은 인코더와 디코더로 구성돼 있다. 따라서 입력이 인코더에 들어가면 셀프 어텐션 기법을 활용해 해당 문장의 정보를 추출하고 이 값을 토대로 디코더에서 출력 문장을 만들어 낸다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IXVebQX56Bo"
   },
   "source": [
    "### 패키지 불러오기\n",
    "- 우선 데이터 전처리 함수 작정을 위한 패키지를 불러온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 35471,
     "status": "ok",
     "timestamp": 1609134912734,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "Xrle2mRw5eLG"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import enum\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from konlpy.tag import Okt # 한글 형태소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AbuZH6A6sIk"
   },
   "source": [
    "### 설정값 지정\n",
    "- 토큰들의 인덱스 값 지정을 하도록 한다. \n",
    "- 특별한 토큰의 의미는 아래와 같다. \n",
    "  + PAD: 어떤 의미도 없는 패딩 토큰\n",
    "  + SOS: 시작 토큰을 의미\n",
    "  + END: 종료 토큰을 의미\n",
    "  + UNK: 사전에 없는 단어를 의미\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 35467,
     "status": "ok",
     "timestamp": 1609134912736,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "jEPI5zeo67P7"
   },
   "outputs": [],
   "source": [
    "FILTERS = \"([~.,!?\\\"':;)(])\" # 특수문자\n",
    "PAD = \"<PAD>\"\n",
    "STD = \"<SOS>\"\n",
    "END = \"<END>\"\n",
    "UNK = \"<UNK>\"\n",
    "\n",
    "PAD_INDEX = 0\n",
    "STD_INDEX = 1\n",
    "END_INDEX = 2\n",
    "UNK_INDEX = 3\n",
    "\n",
    "MARKER = [PAD, STD, END, UNK]\n",
    "CHANGE_FILTER = re.compile(FILTERS)\n",
    "\n",
    "MAX_SEQUENCE = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfM3FhKg6h2j"
   },
   "source": [
    "### 데이터 전처리 함수 정의\n",
    "- 데이터 전처리를 위한 함수를 작성한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 35463,
     "status": "ok",
     "timestamp": 1609134912737,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "kjbxlZwP6BmJ"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    # 판다스를 통해서 데이터를 불러온다.\n",
    "    data_df = pd.read_csv(path, header=0)\n",
    "    # 질문과 답변 열을 가져와 question과 answer에 넣는다.\n",
    "    question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "\n",
    "    return question, answer\n",
    "\n",
    "\n",
    "def data_tokenizer(data):\n",
    "    # 토크나이징 해서 담을 배열 생성\n",
    "    words = []\n",
    "    for sentence in data:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 위 필터와 같은 값들을 정규화 표현식을\n",
    "        # 통해서 모두 \"\" 으로 변환 해주는 부분이다.\n",
    "        sentence = re.sub(CHANGE_FILTER, \"\", sentence)\n",
    "        for word in sentence.split():\n",
    "            words.append(word)\n",
    "    # 토그나이징과 정규표현식을 통해 만들어진\n",
    "    # 값들을 넘겨 준다.\n",
    "    return [word for word in words if word]\n",
    "\n",
    "\n",
    "def prepro_like_morphlized(data):\n",
    "    morph_analyzer = Okt()\n",
    "    result_data = list()\n",
    "    for seq in tqdm(data):\n",
    "        morphlized_seq = \" \".join(morph_analyzer.morphs(seq.replace(' ', '')))\n",
    "        result_data.append(morphlized_seq)\n",
    "\n",
    "    return result_data\n",
    "\n",
    "\n",
    "def load_vocabulary(path, vocab_path, tokenize_as_morph=False):\n",
    "    # 사전을 담을 배열 준비한다.\n",
    "    vocabulary_list = []\n",
    "    # 사전을 구성한 후 파일로 저장 진행한다.\n",
    "    # 그 파일의 존재 유무를 확인한다.\n",
    "    if not os.path.exists(vocab_path):\n",
    "        # 이미 생성된 사전 파일이 존재하지 않으므로\n",
    "        # 데이터를 가지고 만들어야 한다.\n",
    "        # 그래서 데이터가 존재 하면 사전을 만들기 위해서\n",
    "        # 데이터 파일의 존재 유무를 확인한다.\n",
    "        if (os.path.exists(path)):\n",
    "            # 데이터가 존재하니 판단스를 통해서\n",
    "            # 데이터를 불러오자\n",
    "            data_df = pd.read_csv(path, encoding='utf-8')\n",
    "            # 판다스의 데이터 프레임을 통해서\n",
    "            # 질문과 답에 대한 열을 가져 온다.\n",
    "            question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "            if tokenize_as_morph:  # 형태소에 따른 토크나이져 처리\n",
    "                question = prepro_like_morphlized(question)\n",
    "                answer = prepro_like_morphlized(answer)\n",
    "            data = []\n",
    "            # 질문과 답변을 extend을\n",
    "            # 통해서 구조가 없는 배열로 만든다.\n",
    "            data.extend(question)\n",
    "            data.extend(answer)\n",
    "            # 토큰나이져 처리 하는 부분이다.\n",
    "            words = data_tokenizer(data)\n",
    "            # 공통적인 단어에 대해서는 모두\n",
    "            # 필요 없으므로 한개로 만들어 주기 위해서\n",
    "            # set해주고 이것들을 리스트로 만들어 준다.\n",
    "            words = list(set(words))\n",
    "            # 데이터 없는 내용중에 MARKER를 사전에\n",
    "            # 추가 하기 위해서 아래와 같이 처리 한다.\n",
    "            # 아래는 MARKER 값이며 리스트의 첫번째 부터\n",
    "            # 순서대로 넣기 위해서 인덱스 0에 추가한다.\n",
    "            # PAD = \"<PADDING>\"\n",
    "            # STD = \"<START>\"\n",
    "            # END = \"<END>\"\n",
    "            # UNK = \"<UNKNWON>\"\n",
    "            words[:0] = MARKER\n",
    "        # 사전을 리스트로 만들었으니 이 내용을\n",
    "        # 사전 파일을 만들어 넣는다.\n",
    "        with open(vocab_path, 'w', encoding='utf-8') as vocabulary_file:\n",
    "            for word in words:\n",
    "                vocabulary_file.write(word + '\\n')\n",
    "\n",
    "    # 사전 파일이 존재하면 여기에서\n",
    "    # 그 파일을 불러서 배열에 넣어 준다.\n",
    "    with open(vocab_path, 'r', encoding='utf-8') as vocabulary_file:\n",
    "        for line in vocabulary_file:\n",
    "            vocabulary_list.append(line.strip())\n",
    "\n",
    "    # 배열에 내용을 키와 값이 있는\n",
    "    # 딕셔너리 구조로 만든다.\n",
    "    char2idx, idx2char = make_vocabulary(vocabulary_list)\n",
    "    # 두가지 형태의 키와 값이 있는 형태를 리턴한다.\n",
    "    # (예) 단어: 인덱스 , 인덱스: 단어)\n",
    "    return char2idx, idx2char, len(char2idx)\n",
    "\n",
    "def make_vocabulary(vocabulary_list):\n",
    "    # 리스트를 키가 단어이고 값이 인덱스인\n",
    "    # 딕셔너리를 만든다.\n",
    "    char2idx = {char: idx for idx, char in enumerate(vocabulary_list)}\n",
    "    # 리스트를 키가 인덱스이고 값이 단어인\n",
    "    # 딕셔너리를 만든다.\n",
    "    idx2char = {idx: char for idx, char in enumerate(vocabulary_list)}\n",
    "    # 두개의 딕셔너리를 넘겨 준다.\n",
    "\n",
    "    # 예제, [안녕, 너는, 누구야]가 데이터로 들어오면\n",
    "    # word2idx는 {'안녕':0, '너는':1, '누구야':2}가 된다. \n",
    "    # idx2word는 {0:'안녕', 1:'너는', 2:'누구야'}가 된다.\n",
    "    return char2idx, idx2char\n",
    "\n",
    "\n",
    "def enc_processing(value, dictionary, tokenize_as_morph=False):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다.)\n",
    "    sequences_input_index = []\n",
    "    # 하나의 인코딩 되는 문장의 길이를 가지고 있다.(누적된다.)\n",
    "    sequences_length = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "    if tokenize_as_morph:\n",
    "        value = prepro_like_morphlized(value)\n",
    "\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 하나의 문장을 인코딩 할때 가지고 있기 위한 배열이다.\n",
    "        sequence_index = []\n",
    "        # 문장을 스페이스 단위로 자르고 있다.\n",
    "        for word in sequence.split():\n",
    "            # 잘려진 단어들이 딕셔너리에 존재 하는지 보고\n",
    "            # 그 값을 가져와 sequence_index에 추가한다.\n",
    "            if dictionary.get(word) is not None:\n",
    "                sequence_index.extend([dictionary[word]])\n",
    "            # 잘려진 단어가 딕셔너리에 존재 하지 않는\n",
    "            # 경우 이므로 UNK(2)를 넣어 준다.\n",
    "            else:\n",
    "                sequence_index.extend([dictionary[UNK]])\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        if len(sequence_index) > MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE]\n",
    "        # 하나의 문장에 길이를 넣어주고 있다.\n",
    "        sequences_length.append(len(sequence_index))\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_input_index에 넣어 준다.\n",
    "        sequences_input_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
    "\n",
    "    # 함수 로직 요약\n",
    "    # 우선, 정규 표현식을 활용하여 특수문자 모두 제거\n",
    "    # 만약 어떤 단어가 단어 사전에 포함돼 있지 않다면 UNK 토큰을 넣는다. \n",
    "    # 인코더 최대 길이가 5라고 가정하고 다음 예시를 참조한다. \n",
    "    # 인코더 최대 길이보다 긴 경우: \"안녕 우리 너무 오랜만에 만난거 같다.\"\n",
    "    # 인코더 최대 길이보다 긴 경우 입력값: 안녕, 우리, 너무, 오랜만에, 만난거\n",
    "    # 즉, \"같다.\"가 생략된 입력값이 만들어진다. '\n",
    "    # 그런데, 인코더 최대 길이보다 짧은 경우: \"안녕\"\n",
    "    # 인코더 최대 길이보다 짧은 경우 입력값: \"안녕, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>\"\n",
    "    # 함수의 리턴값을 보면 2개의 값이 반환되는 것을 확인할 수 있다. \n",
    "    return np.asarray(sequences_input_index), sequences_length\n",
    "\n",
    "\n",
    "def dec_output_processing(value, dictionary, tokenize_as_morph=False):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다)\n",
    "    sequences_output_index = []\n",
    "    # 하나의 디코딩 입력 되는 문장의\n",
    "    # 길이를 가지고 있다.(누적된다)\n",
    "    sequences_length = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "    if tokenize_as_morph:\n",
    "        value = prepro_like_morphlized(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 하나의 문장을 디코딩 할때 가지고\n",
    "        # 있기 위한 배열이다.\n",
    "        sequence_index = []\n",
    "        # 디코딩 입력의 처음에는 START가 와야 하므로\n",
    "        # 그 값을 넣어 주고 시작한다.\n",
    "        # 문장에서 스페이스 단위별로 단어를 가져와서 딕셔너리의\n",
    "        # 값인 인덱스를 넣어 준다.\n",
    "        sequence_index = [dictionary[STD]] + [dictionary[word] if word in dictionary else dictionary[UNK] for word in sequence.split()]\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        if len(sequence_index) > MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE]\n",
    "        # 하나의 문장에 길이를 넣어주고 있다.\n",
    "        sequences_length.append(len(sequence_index))\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_output_index 넣어 준다.\n",
    "        sequences_output_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한\n",
    "    # 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_output_index), sequences_length\n",
    "\n",
    "\n",
    "def dec_target_processing(value, dictionary, tokenize_as_morph=False):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다)\n",
    "    sequences_target_index = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "    if tokenize_as_morph:\n",
    "        value = prepro_like_morphlized(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 문장에서 스페이스 단위별로 단어를 가져와서\n",
    "        # 딕셔너리의 값인 인덱스를 넣어 준다.\n",
    "        # 디코딩 출력의 마지막에 END를 넣어 준다.\n",
    "        sequence_index = [dictionary[word] if word in dictionary else dictionary[UNK] for word in sequence.split()]\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        # 그리고 END 토큰을 넣어 준다\n",
    "        if len(sequence_index) >= MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE - 1] + [dictionary[END]]\n",
    "        else:\n",
    "            sequence_index += [dictionary[END]]\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_target_index에 넣어 준다.\n",
    "        sequences_target_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_target_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRtKibVB7keW"
   },
   "source": [
    "- 이제 데이터 전처리를 수행한다. \n",
    "- 이번에는 띄어쓰기가 아닌 형태소 단위로 토크나이즈 하는 방식으로 전처리한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 129213,
     "status": "ok",
     "timestamp": 1609135006493,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "3sCLMPhz7oon",
    "outputId": "a0e61ac5-ece1-4c3c-f4a4-8eeb9d9f2dde"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11823/11823 [00:31<00:00, 373.73it/s]\n",
      "100%|██████████| 11823/11823 [00:29<00:00, 394.60it/s]\n",
      "100%|██████████| 11823/11823 [00:29<00:00, 395.66it/s]\n"
     ]
    }
   ],
   "source": [
    "PATH = 'data_in/ChatBotData.csv'\n",
    "VOCAB_PATH = 'data_in/vocabulary.txt'\n",
    "\n",
    "# os.remove(VOCAB_PATH)\n",
    "inputs, outputs = load_data(PATH)\n",
    "char2idx, idx2char, vocab_size = load_vocabulary(PATH, VOCAB_PATH, tokenize_as_morph=True)\n",
    "index_inputs, input_seq_len = enc_processing(inputs, char2idx, tokenize_as_morph=True)\n",
    "index_outputs, output_seq_len = dec_output_processing(outputs, char2idx, tokenize_as_morph=True)\n",
    "index_targets = dec_target_processing(outputs, char2idx, tokenize_as_morph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMwILFtC7Ewg"
   },
   "source": [
    "### 시각화 함수 정의\n",
    "- 모형 시각화를 위한 함수를 정의한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 129512,
     "status": "ok",
     "timestamp": 1609135006801,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "2cVmhr7T7IKh"
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4sfj_fE7EnD"
   },
   "source": [
    "### 학습 데이터 경로 정의\n",
    "- 필요한 학습 데이터 경로를 정의한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 129506,
     "status": "ok",
     "timestamp": 1609135006801,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "6n0ecoJg7Ti1"
   },
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "TRAIN_INPUTS = 'train_inputs.npy'\n",
    "TRAIN_OUTPUTS = 'train_outputs.npy'\n",
    "TRAIN_TARGETS = 'train_targets.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GX3BWnP7dQz"
   },
   "source": [
    "### 랜덤 시드 고정\n",
    "- 실험 재현성을 위해 시드를 고정한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 129502,
     "status": "ok",
     "timestamp": 1609135006802,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "udNhwPg09soW"
   },
   "outputs": [],
   "source": [
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51qJkx9v9vd6"
   },
   "source": [
    "### 학습 데이터 불러오기\n",
    "- 필요한 학습 데이터를 잘 불러오도록 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 130848,
     "status": "ok",
     "timestamp": 1609135008154,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "1P_yAm4r9vFJ"
   },
   "outputs": [],
   "source": [
    "index_inputs = np.load(open(DATA_IN_PATH + TRAIN_INPUTS, 'rb'))\n",
    "index_outputs = np.load(open(DATA_IN_PATH + TRAIN_OUTPUTS , 'rb'))\n",
    "index_targets = np.load(open(DATA_IN_PATH + TRAIN_TARGETS , 'rb'))\n",
    "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U16Lgua89508"
   },
   "source": [
    "### 모델 파라미터 정의\n",
    "- 학습 모델에 대한 파라미터를 정의한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 130846,
     "status": "ok",
     "timestamp": 1609135008158,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "C3gp_DwZ9_ka"
   },
   "outputs": [],
   "source": [
    "char2idx = prepro_configs['char2idx']\n",
    "end_index = prepro_configs['end_symbol']\n",
    "model_name = 'transformer'\n",
    "vocab_size = prepro_configs['vocab_size']\n",
    "BATCH_SIZE = 64\n",
    "MAX_SEQUENCE = 25\n",
    "EPOCHS = 20\n",
    "VALID_SPLIT = 0.1\n",
    "\n",
    "kargs = {'model_name': model_name,\n",
    "         'num_layers': 2,\n",
    "         'd_model': 512,\n",
    "         'num_heads': 8,\n",
    "         'dff': 2048,\n",
    "         'input_vocab_size': vocab_size,\n",
    "         'target_vocab_size': vocab_size,\n",
    "         'maximum_position_encoding': MAX_SEQUENCE,\n",
    "         'end_token_idx': char2idx[end_index],\n",
    "         'rate': 0.1\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjDSbSra-O7b"
   },
   "source": [
    "## 모델 구현을 위한 4가지 모듈\n",
    "- 트랜스포머의 각 모듈을 직접 정의한 후, 인코더와 디코더 모듈을 만들어 본다. \n",
    "- 우선 모델 구현에 앞서 마스킹을 직접 처리하도록 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qCERwBV_ma4"
   },
   "source": [
    "### Masking\n",
    "- 시퀀스의 일괄 처리에서 모든 패드 토큰을 마스킹 한다. \n",
    "- 이렇게 하면 모델이 패딩을 입력으로 처리하지 않는다. \n",
    "- 마스크는 패드 값이 0이 있는 위치를 나타낸다. \n",
    "  + 이 위치에 있으면 1이 출력되고, 그렇지 않으면 0이 출력됩니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 136333,
     "status": "ok",
     "timestamp": 1609135013650,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "0BqAhn_t-KuG",
    "outputId": "036be7bf-3ee4-4c6d-fb88-ef23bc189d6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "# 예제 코드\n",
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqN4wi7HAQqg"
   },
   "source": [
    "- 다음 함수는 미래의 토큰을 순차적으로 마스크하는 데 사용된다. (순방향 마스크 어텐션)\n",
    "- 즉, 마스크는 사용하지 말아야 할 입력값을 알게 해준다. \n",
    "  + 삼각형 형태의 행렬을 만들고 마스킹할 영역의 값은 1, 아닌 영역은 0으로 만들면 된다. \n",
    "  + 행렬의 아래쪽 삼각형 영역이 0이 되는 하삼각행렬을 만들 텐데, 이를 만드는 방법은 `tf.linalg.bandpart(입력행렬, -1, 0)`을 실행한다. \n",
    "  + 입력행렬은 모든 값이 1인 행렬을 만든다. \n",
    "  + 이렇게 하 삼각행렬을 만들면 마스킹하고자 하는 영역에 1 값을 주기 위해 상수 1로부터 만들어진 하삼각행렬을 뺀다. 상수 1을 빼는 연산은 행렬에 대해 전체 행렬에 연산이 적용되는 브로드캐스팅 연산이라고 보면 된다. \n",
    "- 이것은 세 번째 단어를 예측하기 위해 첫 번째 단어와 두 번째 단어만 사용된다는 것을 의미한다. 네 번째 단어를 예측하는 것과 유사하게, 첫 번째, 두 번째, 세 번째 단어만 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 136324,
     "status": "ok",
     "timestamp": 1609135013651,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "dbBMZhSLAZ3f",
    "outputId": "d031a02c-c04e-41d3-ead5-684a0652e325"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5LGvAAIBGbh"
   },
   "source": [
    "- 위 두가지 함수를 조합하여 마스크를 생성한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 136315,
     "status": "ok",
     "timestamp": 1609135013651,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "cA2dkMvuA-3z"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gxbyIugBSKT"
   },
   "source": [
    "- Masking 처리를 완료한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 136308,
     "status": "ok",
     "timestamp": 1609135013652,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "0-IgplFwBQxs"
   },
   "outputs": [],
   "source": [
    "enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(index_inputs, index_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTLW4WNKBce3"
   },
   "source": [
    "### 포지셔널 인코딩\n",
    "- 포지션 인코딩(Positional Encoding)은 트랜스포머 모델에 순서 정보가 반영되지 않는 문제를 해결하기 위해 사용한 기법이다. \n",
    "- 포지션 인코딩 수식은 다음과 같다. \n",
    "- 첫번째 수식\n",
    "$$ PE_{(pos, 2i)} = sin(\\frac{pos}{10000^{\\frac{2i}{d_{model}}}}) $$\n",
    "- 위 수식은 피처 차원에서 인덱스가 짝수인 경우에 대해 사인 함수값을 할당하는 것이다. \n",
    "\n",
    "- 두번째 수식\n",
    "$$ PE_{(pos, 2i+1)} = cos(\\frac{pos}{10000^{\\frac{2i}{d_{model}}}}) $$\n",
    "- 위 수식은 반대로 홀수인 경우에 코사인 함수값을 할당하는 것이다. \n",
    "- 사인 함수와 코사인 함수 안에 있는 식은 각 시퀀스 위치에 따라 피처 차원 인덱스에 각자 위치 정보를 달리 주고자 하는 의도를 가지고 있다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 136984,
     "status": "ok",
     "timestamp": 1609135014333,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "8yEukTytBhRP"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * i//2) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mf1E6L9rDkoN"
   },
   "source": [
    "- 포지션 임베딩을 만들 행렬을 구성하기 위해 `get_angles` 함수를 선언한다. \n",
    "  + 이 함수가 $\\frac{pos}{10000^{\\frac{2i}{d_{model}}}}$ 값을 만드는 함수다. \n",
    "  + 각 입력의 파라미터는 `pos`, `i`, `d_model`로 돼 있다. \n",
    "- `pos`에는 포지션에 대한 인덱스 위치 리스트를 입력하고, `i`에는 차원에 대한 리스트를 입력한다. \n",
    "- 이렇게 하여 각 순서에 따른 각도값을 얻을 수 있다. \n",
    "- 이제 `get_angles`를 가지고 포지션 임베딩을 만들어 본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 136979,
     "status": "ok",
     "timestamp": 1609135014334,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "R9HCnLECDjlw"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # 짝수\n",
    "    # 0::2의 뜻은 2씩 증가하는 인덱스의 배열 값만 출력\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # 홀수\n",
    "    # 1::2의 뜻은 1에서부터 2씩 증가하는 인덱스의 배열 값만 출력된다. \n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # 이렇게 사인, 코사인 함수를 적용한 값은 배열에 할당한다. \n",
    "    # 인코더 및 디코더 레이어에서 바로 활용할 수 있도록 `np.newaxis`를 사용하는데, 이는 새로운 차원을 만드는 것을 의미한다. \n",
    "    # 새로운 차원을 만들려면 포지션 임베딩 행렬의 차원은 [배치 차원 X 시퀀스 차원 X 피처 차원]으로 구성된다. \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    # 이렇게 구성을 마친 배열은 `tf.cast`를 통해 상수가 되어 모델 그래프에 활용한다. \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvAdtcTyFAiA"
   },
   "source": [
    "- `gen_angels` 함수의 결괏값을 출력하면 포지션과 차원별로 각기 다른 값이 순차적으로 할당돼 있다. \n",
    "- 이제 이러한 값들을 짝수 차원에서는 사인 함수를, 홀수 차원에서는 코사인 함수를 적용한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 136965,
     "status": "ok",
     "timestamp": 1609135014335,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "BpAvvvEbBnMa",
    "outputId": "345c9537-463e-422b-d5d7-d52a5ecbb425"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print(pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYfPu-uAGyw9"
   },
   "source": [
    "### 스케일 내적 어텐션\n",
    "- 기본적인 내적 어텐션의 입력은 세 가지로 구성이 된다. \n",
    "- query(질의), key(키), value(값)로 들어온다. \n",
    "  + 네이버 영어 사전 검색 방법을 떠올려 보자. \n",
    "  + 찾고자 하는 단어는 `query`가 되고, 사전에 등록되어 있는 단어는 `key`가 된다. 마지막으로, `key`에 해당하는 단어의 의미는 `value`로 볼 수 있다. \n",
    "- 위 개념을 어텐션으로 구현하는 것이다. \n",
    "  + 출처: https://wikidocs.net/31379\n",
    "![](https://wikidocs.net/images/page/31379/transformer14_final.PNG)\n",
    "- 연산 과정을 살펴본다. \n",
    "- 먼저 특정 단어에 대해 다른 모든 단어와 내적해서 어텐션 스코어값을 구한다. \n",
    "  + 즉, `query`에 대해 다른 모든 `key`와 내적해서 어텐션 스코어를 구하는 것이다. \n",
    "  + 이렇게 구한 스코어에 소프트맥스 함수를 적용해 확률값으로 만든 후 다시 다른 모든 단어들, 즉 `value`에 각각 곱해서 `query`와의 관계가 적용된 `value`값으로 만든다. \n",
    "  + 이제 이 값을 모두 더하면 `query`에 대한 문맥 벡터가 된다. \n",
    "- 여기까지는 사실 셀프 어텐션의 구조와 동일하지만, 중간에 크기를 조정하는 과정(`scaling`)이 추가된 것이다. \n",
    "  + 수식은 아래와 같다. \n",
    "$$ Attention(Q, K, V)= softmax(\\frac{AK^{T}}{\\sqrt{d_{k}}})V$$\n",
    "- 위 수식처럼 `query`와 `key`를 내적한 값에 `key` 벡터의 차원 수를 제곱근한 값으로 나눈 후 소프트맥스 함수를 적용한다.\n",
    "  + 여기에서 $D_{k}$는 `key` 벡터의 차원 수를 의미한다. \n",
    "- 내적 어텐션 그래프는 다음과 같다. \n",
    "![](https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png)\n",
    "- (1) 위 그림에서 확인할 수 있는 것은 먼저 Q(query)벡터와 K(key)벡터에 대해 어텐션 스코어 맵을 만들고 크기를 조정한다. (2) 선택적으로 마스크(mask)를 적용한다. (3) 이 값에 소프트맥스 함수를 적용한 후 마지막으로 `value`에 대해 가중합을 적용한다. \n",
    "- 내적 어텐션에 대한 함수는 다음과 같다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUVPDzMuj9eU"
   },
   "source": [
    "### 순방향 마스크 어텐션(Subsequent Masked Attention)\n",
    "- 문장을 예측하는 과정에서 디코더 부분에 입력이 들어가는데, 순환 신경망 구조의 경우 자신보다 앞에 있는 단어만 참고해서 단어를 예측하는 반면, 트랜스포머는 전체 문장이 들어가기 때문에 위치와 상관없이 모든 단어를 참고해서 예측을 한다. \n",
    "  + 이론적으로는 무언가 이상하다. 자기 자신도 예측을 하지 않았는데, 뒤에 있는 단어를 어떻게 예측한다는 것인가?\n",
    "  + 이러한 문제를 해결하기 위해 고안된 기법이 마스크 기법이다. (Masking 참조)\n",
    "- 마스크의 목적은 무엇인가?\n",
    "  + 자신보다 뒤에 나오는 단어를 참조하지 못하도록 행렬의 아래쪽 삼각형 부분을 제외한 값에 마스킹 처리를 해주는 것이다. \n",
    "  + 이를 구현하려면 아래쪽 삼각형 부분을 제외한 값에 매우 작은 값을 넣으면 된다. 여기서는 그 값으로 -10의 9승인 `-1e9`값을 넣어준다. 이것은 특별히 의미가 있는 값이 아니라 매우 작은 어떤 값을 넣어주려는 것이다. \n",
    "- 이제 앞에서 만든 `mask`를 이용해 `padding`이라는 변수를 만든다. \n",
    "- 이제 이렇게 넣어준 값에 소프트맥스 함수에 매우 작은 음수값을 넣어 0값에 수렴하게 만들고, 이렇게 마스킹 처리된 부분을 참고할 수 없도록 하는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 136957,
     "status": "ok",
     "timestamp": 1609135014336,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "GnpFr6_UyReQ"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead) \n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # 스케일링\n",
    "    # dk의 루트값으로 나눠준다.\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywb02qJ3yVgk"
   },
   "source": [
    "### 멀티 헤드 어텐션\n",
    "- 멀티 헤드 어텐션은 어텐션 맵을 여럿 만들어 다양한 특징에 대한 어텐션을 볼 수 있도록 하는 방법이다. \n",
    "  + 그림 출처: https://paperswithcode.com/method/multi-head-attention\n",
    "![](https://paperswithcode.com/media/methods/multi-head-attention_l1A3G7a.png)\n",
    "- 내적 어텐션에서 본 query, key, value에 대한 특징값을 헤드 수만큼 나눠서 리니어(Linear) 레이어를 거쳐 내적 어텐션(`Scaled Dot-Product`)를 구해서 다시 합치는 과정을 거친다. \n",
    "- 멀티 헤드 어텐션의 구현은 다음과 같다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 136951,
     "status": "ok",
     "timestamp": 1609135014336,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "OkdYgWdl1SBI"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    # **kargs: 입력 파라미터로 받는다. \n",
    "    # d_model: 어텐션을 연산할 때, `key`, `query`, `value`에 대한 차원을 정의하기 위한 파라미터\n",
    "    # num_heads: 어텐션 헤드 수를 정의하기 위한 파라미터 \n",
    "\n",
    "    # 멀티헤드 어텐션에 대한 설정\n",
    "    def __init__(self, **kargs):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = kargs['num_heads']\n",
    "        self.d_model = kargs['d_model']\n",
    "\n",
    "        # d_model의 차원 수는 헤드 개수만큼 나눠져야 하기 때문에 나머지가 발생하면 안된다. \n",
    "        # assert 구문을 활용해 두 변수를 대상으로 나눗셈 시, 에러가 발생하도록 구현한다. \n",
    "        assert self.d_model % self.num_heads == 0\n",
    "\n",
    "\n",
    "        self.depth = self.d_model // self.num_heads\n",
    "\n",
    "        # 어텐션에 필요한 query, key, value 값을 의미한다. \n",
    "        self.wq = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wk = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wv = tf.keras.layers.Dense(kargs['d_model'])\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(kargs['d_model'])\n",
    "\n",
    "    # query, key, value에 대한 벡터를 헤드 수 만큼 분리할 수 있게 하는 함수\n",
    "    # [배치 차원 X 시퀀스 차원 X 피처 차원]으로 구성된 벡터를 [배치 차원 X 헤드 차원 X 시퀀스 차원 X 피처 차원]으로 변환하는 역할 수행\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        # reshape를 활용하여 피처 차원을 헤드 수 만큼 분리할 수 있다. \n",
    "        # 입력값으로 batch_size를 고정값이 아닌 변동 입력값으로 넣어주는 이유는 모델 학습 시, 입력하는 도중에 입력 배치 데이터의 시퀀스 길이가 매번 바뀌는 경우가 있을 수 있기 때문에 그렇다. \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "\n",
    "        # 시퀀스, 헤드 차원만 바꿀 수 있도록 한다. \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 멀티헤드 어텐션이 동작하는 call 함수를 구현한다. \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQXNDK3bViQB"
   },
   "source": [
    "### 포지션-와이즈 피드 포워드 네트워크\n",
    "- 셀프 어텐션 레이어를 거친 다음 피드 포워드 네트워크를 거치게 돼 있다. \n",
    "- 네트워크는 한 문장에 있는 단어 토큰 벡터 각각에 대해 연산하는 네트워크로서 논문에서는 포지션-와이즈 피드 포워드 네트워크(Position-Wise Feedforward Network)라 표현한다. \n",
    "\n",
    "$$ FFN(x) = max(0, xW_{1} + b_{1})W_{2} + b_{2} $$\n",
    "\n",
    "- 위 수식과 같이 네트워크를 구성하는 데 두 개의 리니어 레이어를 거치고 그 사이 활성화 함수로 `Relu` 함수를 활용한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 136945,
     "status": "ok",
     "timestamp": 1609135014337,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "fRn4w9SrWax7"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(**kargs):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(kargs['dff'], activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(kargs['d_model'])  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NCp12acXXZS"
   },
   "source": [
    "- 위 연산은 `Encoder`와 `Decoder`에서 구현되는 것을 다시 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NqQSQpIXeWB"
   },
   "source": [
    "### 리지듀얼 커넥션\n",
    "- 리지듀얼 커넥션에 관한 그림은 다음과 같다. \n",
    "  + 그림출처: https://wikidocs.net/images/page/31379 \n",
    "![](https://wikidocs.net/images/page/31379/transformer22.PNG)\n",
    "- 위 그림과 같이 입력 정보 `x`가 있고, 네트워크 레이어를 거쳐 나온 정보 `F(x)`가 있다고 하면 이 두 정보를 더해 앞에 있던 정보 `x`를 보전한다. \n",
    "- 어떤 함수 F(x)가 트랜스포머에서는 서브층에 해당됩니다. \n",
    "  + 다시 말해 잔차 연결은 서브층의 입력과 출력을 더하는 것을 말합니다.\n",
    "  + 트랜스포머에서 서브층의 입력과 출력은 동일한 차원을 갖고 있으므로, 서브층의 입력과 서브층의 출력은 덧셈 연산을 할 수 있습니다.\n",
    "- 위 코드는 `Encoder`와 `Decoder` 에서 다시한번 주석으로 언급하도록 한다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppHhjzG_Z5hr"
   },
   "source": [
    "## 인코더와 디코더 구현\n",
    "- 아래 그림은 지금까지 배운 모듈이 어떻게 트랜스포어의 레이어를 구성하는지 살펴보는 예제라고 보면 된다. \n",
    "\n",
    "![](https://paperswithcode.com/media/methods/new_ModalNet-21.jpg)\n",
    "- 왼쪽이 인코더, 오른쪽이 디코더가 된다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzcpQA7XapfZ"
   },
   "source": [
    "### 인코더 레이어 클래스 구현\n",
    "- 인코더 레이어 클래스를 구현하도록 한다. \n",
    "- 멀티 헤드 어텐션 레이어와 피드 포워드 네트워크로 한 레이어를 구성하고, 각 레이어에는 리지듀얼 커넥션이 함께 적용 되어 있다. \n",
    "  + 연산할 레이어 피드 포워드 네트워크와 레이어 노멀라이즈(=정규화)를 각각 생성하는데, 각 레이어별 뉴런을 노멀라이즈하는 역할이라고 이해하면 된다. \n",
    "  + 이 부분은 트랜스포머 네트워크의 전체 구조에서 `Add & Norm`에 해당하는 부분으로 보면 된다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 136940,
     "status": "ok",
     "timestamp": 1609135014338,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "2cAxJ1etakk9"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(**kargs)\n",
    "\n",
    "        # 리지듀얼 커넥션\n",
    "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JW_XFEjwnjKf"
   },
   "source": [
    "- `__init__` 함수\n",
    "  +  멀티 헤드 어텐션에 적용될 출력 차원 수 `d_model`과 헤드 수 `num_heads`를 적용한다. \n",
    "  + 포지션 와이즈 피드 포워드 네트워크의 차원 수 `dff`를 적용한다. \n",
    "  + 이 세 파라미터로 필요한 레이어의 출력 차원 수를 정의한다. \n",
    "  + 즉, `MultiHeadAttention` 클래스를 활용해 멀티 헤드 어텐션 레이어를 생성하고, `point_wise_feed_forward_network`를 활용해 피드 포워드 네트워크를 생성한다. 마지막으로 레이어 노멀라이제이션과 드롭아웃 레이어를 생성한다. \n",
    "  + 이를 활용하여 `call` 함수에서 연산하도록 한다. \n",
    "- `call` 함수\n",
    "  + 입력 벡터인 `x`와 패딩 마스크 `mask`를 입력 파라미터로 정의\n",
    "  + 먼저 멀티 헤드 어텐션 레이어인 self.mha를 통과한다. \n",
    "  + 리지듀얼 커넥션을 위해 `attn_output`과 입력값 `x`를 더하고, `self.layernorm1`을 통해 레이어 노멀라이제이션을 수행한다. \n",
    "  + 이 결괏값은 `out1`에 할당한다. \n",
    "  + 동일한 방법으로 와이즈 피드 포워드 네트워크를 생성 후, out2에 할당한 후에 인코더 레이어에 출력한다. \n",
    "  + `dropout`을 통해 모델에 `generalization`을 할 수 있도록 도와 준다. \n",
    "- 이렇게 구현한 클래스의 의미는  `여러 개의 인코더를 쎃을 수 있도록 한 것`이다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjcXnIkN-bcr"
   },
   "source": [
    "### 인코더 클래스 구현\n",
    "- 인코더를 구현하면 여러 개의 인코더 레이어를 쌓을 수 있도록 준비한 것이다. \n",
    "- 이제 `Encoder` 클래스로 인코더 레이어를 쌓고, 워드 임베딩과 포지션 임베딩 정보를 받아 텍스트에 대한 컨텍스트 정보를 만든다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 847,
     "status": "ok",
     "timestamp": 1609138767435,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "EcXXR2b9-sIt"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # num_layers: 인코더 레이어의 수\n",
    "        # d_model: 워드 임베딩과 포지션 임베딩 차원 수를 결정\n",
    "        self.d_model = kargs['d_model']\n",
    "        self.num_layers = kargs['num_layers']\n",
    "\n",
    "        # 워드 임베딩의 사전 수를 입력: input_vocab_size\n",
    "        # 포지션 인코더의 최대 시퀀스 길이 지정: maximum_position_encoding\n",
    "        self.embedding = tf.keras.layers.Embedding(kargs['input_vocab_size'], self.d_model)\n",
    "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(**kargs) \n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "    def call(self, x, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # 포지션 임베딩의 경우 행렬의 크기가 고정돼 있고, 워드 임베딩의 경우 입력 길이에 따라 가변적\n",
    "        # 임베딩이 할당된 후에 임베딩 차원수의 제곱근만큼에 대한 가중치를 곱한다. \n",
    "        # 이 연산 과정은 각 워드 임베딩에 대해 스케일을 맞추기 위한 것이다. \n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdhlMUZIAIqN"
   },
   "source": [
    "### 디코더 레이어 클래스 구현\n",
    "- 전체적인 구조는 인코더(그림 왼쪽)와 비슷하다. \n",
    "![](https://paperswithcode.com/media/methods/new_ModalNet-21.jpg)\n",
    "- 다른 점은 인코더의 경우 하나의 블록이 2개의 레이어로 구성되어 있지만, 디코더의 경우 총 3개의 레이어로 구성돼 있다. \n",
    "  + 두개의 어텐션과, 하나의 피드 포워드 레이어로 구성돼 있다. \n",
    "- 첫번째 어텐션은 디코더의 입력 사이의 관계 계산하는 셀프 어텐션 구조\n",
    "  + 마스크 어텐션은, 말 그대로 예측을 해야 하는 디코더에서 특정 단어 이후의 단어를 참고하지 않도록 말한 마스크 기법을 의미\n",
    "- 두번째 어텐션은 인코더의 결과값이 들어는데, 즉 인코더와 디코더의 관계를 확인하는 구조\n",
    "  + 인코더 부분과 동일하게 피드 포워드 레이어를 적용하면 하나의 디코더 블록이 완성된다.\n",
    "\n",
    "- 이제 코드로 구현한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 819,
     "status": "ok",
     "timestamp": 1609138979284,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "HYPGlgRzB2Xd"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(**kargs)\n",
    "        self.mha2 = MultiHeadAttention(**kargs)\n",
    "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout3 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        # 첫번째 레이어\n",
    "        # 디코더 벡터를 가지고 셀프 어텐션 연산을 하는 부분\n",
    "        # 인코더 연산 + 리지듀얼 커녁션 + 레이어 노멀라이즈\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        # 두번째 레이어\n",
    "        # 인코더 정보와 디코더 정보를 가지고 어텐션을 적용한다. \n",
    "        # 즉, 인코더의 결괏값과의 관계를 확인하는 구조다. \n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        # 리지듀얼 커넥션 + 피드 포워드 네트워크 연산\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkNLFXZhJki4"
   },
   "source": [
    "### 디코더 클래스 구현\n",
    "- 기존 인코더 레이어와 똑같다. \n",
    "- 다만, 인코더 정보 벡터와 순방뱡 어텐션 마스크를 추가로 입력받는디."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1609138980801,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "QMpEupT7JePT"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = kargs['d_model']\n",
    "        self.num_layers = kargs['num_layers']\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(kargs['target_vocab_size'], self.d_model)\n",
    "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], self.d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(**kargs) \n",
    "                           for _ in range(self.num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXWcH2hsJcTb"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfXoDkYbGgkH"
   },
   "source": [
    "## 트랜스 모델 클래스 구현\n",
    "- 이제 인코더와 디코더 모듈을 바탕으로 시퀀스 투 시퀀스 모델 형태로 구현한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1609138092867,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "2VM7lqFQGn25"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Transformer, self).__init__(name=kargs['model_name'])\n",
    "\n",
    "        # 마지막 `end_token`에 대한 인덱스 값을 저장하는 변수로써 `inference` 함수에서 `end_token` 이후로는 더 이상 추론 모델을 하지 않도록 하는 역할을 한다.\n",
    "        self.end_token_idx = kargs['end_token_idx']\n",
    "\n",
    "        # 인코더 레이어 선언\n",
    "        self.encoder = Encoder(**kargs)\n",
    "\n",
    "        # 디코더 레이어 선언\n",
    "        self.decoder = Decoder(**kargs)\n",
    "        \n",
    "        # 출력 피드 포워드 레이어 선언\n",
    "        self.final_layer = tf.keras.layers.Dense(kargs['target_vocab_size'])\n",
    "\n",
    "    def call(self, x):\n",
    "        \n",
    "        # 인코더와 디코더에 들어갈 값\n",
    "        inp, tar = x\n",
    "        \n",
    "        # 패딩 마스크, 디코더에서 사용할 순방향 마스크 할당\n",
    "        # 이 입력값으로 인코더, 디코더, 피드 포워드 네트워크를 거쳐 출력한다. \n",
    "        # 이렇게 하면 출력에서는 입력에 대한 디코더 출력값을 받을 수 있도록 한다. \n",
    "        # 그리고, 이 출력 값을 정답 데이터와 비교해서 로스값을 구한다. \n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "        enc_output = self.encoder(inp, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, _ = self.decoder(\n",
    "            tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output\n",
    "    \n",
    "    def inference(self, x):\n",
    "        # 기본적으로 call 함수와 비슷하다. \n",
    "        inp = x\n",
    "        tar = tf.expand_dims([STD_INDEX], 0)\n",
    "\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)        \n",
    "        enc_output = self.encoder(inp, enc_padding_mask)\n",
    "        \n",
    "        predict_tokens = list()\n",
    "\n",
    "        # 디코더에 입력할 시퀀스를 매번 생성하는 코드이며, `end_token`이 나오면 생성을 멈춘다. \n",
    "        for t in range(0, MAX_SEQUENCE):\n",
    "            dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "            final_output = self.final_layer(dec_output)\n",
    "            outputs = tf.argmax(final_output, -1).numpy()\n",
    "            pred_token = outputs[0][-1]\n",
    "            if pred_token == self.end_token_idx:\n",
    "                break\n",
    "            predict_tokens.append(pred_token)\n",
    "            tar = tf.expand_dims([STD_INDEX] + predict_tokens, 0)\n",
    "            _, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "            \n",
    "        return predict_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxVC7zaBIyrv"
   },
   "source": [
    "### 평가 지표 함수 구현 \n",
    "- 우선 모델의 평가 지표를 산출하는 함수를 구현한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 868,
     "status": "ok",
     "timestamp": 1609138736763,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "ng1NcRRfI5uB"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def loss(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
    "    pred *= mask    \n",
    "    acc = train_accuracy(real, pred)\n",
    "\n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ielTcqsFJL4Y"
   },
   "source": [
    "### 모델 정의\n",
    "- 모델을 정의한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1609138985346,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "O-fZ0ybBJNwj"
   },
   "outputs": [],
   "source": [
    "model = Transformer(**kargs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              loss=loss,\n",
    "              metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jM_YGAhlJJTb"
   },
   "source": [
    "### Call Back 선언\n",
    "- 과적합 방지를 위해 `CallBack` 선언을 진행한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 806,
     "status": "ok",
     "timestamp": 1609139066897,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "s-S4lCa2KL0B",
    "outputId": "681274ba-d3bd-4ee5-97ac-e4bf83d09810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_out/transformer -- Folder create complete \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=10)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\n",
    "\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmtX_7zWKZ7K"
   },
   "source": [
    "### 모형 학습\n",
    "- 이제 모형을 학습한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 735928,
     "status": "ok",
     "timestamp": 1609139906641,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "FD7Igd4DKb4B",
    "outputId": "2f72da1c-8a86-4c44-9d0f-591bb81d0ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "167/167 [==============================] - 47s 217ms/step - loss: 1.7586 - accuracy: 0.8082 - val_loss: 1.6887 - val_accuracy: 0.8078\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80776, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 2/20\n",
      "167/167 [==============================] - 35s 211ms/step - loss: 1.3753 - accuracy: 0.8081 - val_loss: 1.5989 - val_accuracy: 0.8111\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.80776 to 0.81113, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 3/20\n",
      "167/167 [==============================] - 35s 210ms/step - loss: 1.2364 - accuracy: 0.8126 - val_loss: 1.5313 - val_accuracy: 0.8168\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.81113 to 0.81676, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 4/20\n",
      "167/167 [==============================] - 35s 210ms/step - loss: 1.1309 - accuracy: 0.8181 - val_loss: 1.5040 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.81676 to 0.82218, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 5/20\n",
      "167/167 [==============================] - 35s 208ms/step - loss: 1.0221 - accuracy: 0.8235 - val_loss: 1.4805 - val_accuracy: 0.8272\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.82218 to 0.82725, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 6/20\n",
      "167/167 [==============================] - 35s 209ms/step - loss: 0.9162 - accuracy: 0.8286 - val_loss: 1.4772 - val_accuracy: 0.8322\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.82725 to 0.83224, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 7/20\n",
      "167/167 [==============================] - 35s 208ms/step - loss: 0.8458 - accuracy: 0.8335 - val_loss: 1.4869 - val_accuracy: 0.8372\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.83224 to 0.83720, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 8/20\n",
      "167/167 [==============================] - 35s 208ms/step - loss: 0.7377 - accuracy: 0.8385 - val_loss: 1.4840 - val_accuracy: 0.8422\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.83720 to 0.84216, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 9/20\n",
      "167/167 [==============================] - 35s 208ms/step - loss: 0.6555 - accuracy: 0.8435 - val_loss: 1.4999 - val_accuracy: 0.8472\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.84216 to 0.84717, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 10/20\n",
      "167/167 [==============================] - 35s 209ms/step - loss: 0.5778 - accuracy: 0.8485 - val_loss: 1.5161 - val_accuracy: 0.8522\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.84717 to 0.85221, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 11/20\n",
      "167/167 [==============================] - 35s 211ms/step - loss: 0.5082 - accuracy: 0.8535 - val_loss: 1.5095 - val_accuracy: 0.8573\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.85221 to 0.85732, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 12/20\n",
      "167/167 [==============================] - 35s 208ms/step - loss: 0.4361 - accuracy: 0.8586 - val_loss: 1.5377 - val_accuracy: 0.8624\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.85732 to 0.86242, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 13/20\n",
      "167/167 [==============================] - 35s 209ms/step - loss: 0.3740 - accuracy: 0.8637 - val_loss: 1.5571 - val_accuracy: 0.8675\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.86242 to 0.86752, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 14/20\n",
      "167/167 [==============================] - 35s 208ms/step - loss: 0.3160 - accuracy: 0.8688 - val_loss: 1.5722 - val_accuracy: 0.8725\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.86752 to 0.87252, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 15/20\n",
      "167/167 [==============================] - 34s 207ms/step - loss: 0.2675 - accuracy: 0.8737 - val_loss: 1.5928 - val_accuracy: 0.8774\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.87252 to 0.87739, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 16/20\n",
      "167/167 [==============================] - 35s 207ms/step - loss: 0.2170 - accuracy: 0.8786 - val_loss: 1.6046 - val_accuracy: 0.8821\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.87739 to 0.88212, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 17/20\n",
      "167/167 [==============================] - 35s 207ms/step - loss: 0.1818 - accuracy: 0.8833 - val_loss: 1.6292 - val_accuracy: 0.8867\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.88212 to 0.88667, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 18/20\n",
      "167/167 [==============================] - 35s 207ms/step - loss: 0.1505 - accuracy: 0.8877 - val_loss: 1.6483 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.88667 to 0.89099, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 19/20\n",
      "167/167 [==============================] - 35s 209ms/step - loss: 0.1241 - accuracy: 0.8920 - val_loss: 1.6703 - val_accuracy: 0.8951\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.89099 to 0.89509, saving model to ./data_out/transformer/weights.h5\n",
      "Epoch 20/20\n",
      "167/167 [==============================] - 35s 208ms/step - loss: 0.0984 - accuracy: 0.8960 - val_loss: 1.6781 - val_accuracy: 0.8990\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.89509 to 0.89895, saving model to ./data_out/transformer/weights.h5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([index_inputs, index_outputs], index_targets, \n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                    validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_vZoYRAKfbh"
   },
   "source": [
    "### 모형 결과에 대한 결과\n",
    "- 성능 그래프를 출력한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 736398,
     "status": "ok",
     "timestamp": 1609139907127,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "t2LApH0bKlEX",
    "outputId": "979f1347-72e3-4969-9aad-39df049cdda3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 736396,
     "status": "ok",
     "timestamp": 1609139907128,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "oRldE69UKmlv",
    "outputId": "1ee8abbd-c73e-43db-ed06-52295cb77ce5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CbaR_lQKobA"
   },
   "source": [
    "## 모형 결과 테스트\n",
    "- 저장된 모형을 불러와서 테스트를 진행한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1422,
     "status": "ok",
     "timestamp": 1609140074864,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "5hATe2I_Ksz3",
    "outputId": "c812d134-93df-466c-e66a-3a5537ff090f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하늘 만큼 땅 만큼 축하 해 요\n"
     ]
    }
   ],
   "source": [
    "DATA_OUT_PATH = './data_out/'\n",
    "SAVE_FILE_NM = 'weights.h5'\n",
    "\n",
    "model.load_weights(os.path.join(DATA_OUT_PATH, model_name, SAVE_FILE_NM))\n",
    "\n",
    "char2idx = prepro_configs['char2idx']\n",
    "idx2char = prepro_configs['idx2char']\n",
    "\n",
    "text = \"승진 선물로 뭐가 좋을까요?\"\n",
    "test_index_inputs, _ = enc_processing([text], char2idx)\n",
    "outputs = model.inference(test_index_inputs)\n",
    "\n",
    "print(' '.join([idx2char[str(o)] for o in outputs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CWwrT5_a7H4"
   },
   "source": [
    "- "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPESsU9KqRdyDGICG4n3ZL0",
   "collapsed_sections": [],
   "name": "step_03_transformer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
