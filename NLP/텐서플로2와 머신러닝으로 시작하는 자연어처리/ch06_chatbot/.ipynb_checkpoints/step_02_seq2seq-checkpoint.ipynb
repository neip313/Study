{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geWXPvDBZ0pn"
   },
   "source": [
    "## 데이터셋 소개\n",
    "- 한국어 챗봇 데이터는 거의 없다. \n",
    "  + 다행히, 한글로도 챗봇을 만들수 있도록 `Chatbot_data_for_Korean v1.0` 데이터셋이다. \n",
    "- 총 11,876개의 데이터로 구성돼 있다. \n",
    "  + 각 데이터는 질문과 그에 대한 대답, 그리고 주제에 대한 라벨값을 가진다. \n",
    "    * 0은 일상 대화, 1은 긍정, 2는 부정의 주제를 의미한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mxmlN1EgEGN"
   },
   "source": [
    "## 데이터 분석\n",
    "- 챗봇 데이터를 분석해보자. \n",
    "- 데이터 출처: https://github.com/songys/Chatbot_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bcv5EKRyjTck"
   },
   "source": [
    "### 구글 코랩과 구글 드라이브 연동\n",
    "- 우선 데이터가 있는 폴더와 연동한다. \n",
    "> Note: 런타임을 GPU로 바꾸는 것을 잊지 않는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 14580,
     "status": "error",
     "timestamp": 1609034045787,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "1wwqlWe7ZvR2",
    "outputId": "afec8b3c-aa6a-4c34-ccd8-f1ba7e3558f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \"\"\"\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7d58c536cd4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mROOT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive\"\u001b[0m     \u001b[0;31m# 드라이브 기본 경로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# print content of ROOT (Optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# 드라이브 기본 경로 Mount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mMY_GOOGLE_DRIVE_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'My Drive/Colab Notebooks/강림직업전문학교/프로젝트/NLP_자연어처리/ch06_챗봇_만들기/'\u001b[0m \u001b[0;31m# 프로젝트 경로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from google.colab import drive # 패키지 불러오기 \n",
    "from os.path import join  \n",
    "\n",
    "ROOT = \"/content/drive\"     # 드라이브 기본 경로\n",
    "print(ROOT)                 # print content of ROOT (Optional)\n",
    "drive.mount(ROOT)           # 드라이브 기본 경로 Mount\n",
    "\n",
    "MY_GOOGLE_DRIVE_PATH = 'My Drive/Colab Notebooks/강림직업전문학교/프로젝트/NLP_자연어처리/ch06_챗봇_만들기/' # 프로젝트 경로\n",
    "PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH) # 프로젝트 경로\n",
    "print(PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1887,
     "status": "ok",
     "timestamp": 1608977671862,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "c2nDwL2UjOWQ",
    "outputId": "7d82f3db-b8f2-4b13-ca80-7c6b5005dc92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/강림직업전문학교/프로젝트/NLP_자연어처리/ch06_챗봇_만들기\n"
     ]
    }
   ],
   "source": [
    "%cd \"{PROJECT_PATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jx14uFbik8IB"
   },
   "source": [
    "### 데이터 불러오기 및 확인\n",
    "- Pandas 라이브러리를 활용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 1518,
     "status": "ok",
     "timestamp": 1608977675843,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "WxnhdWyblCtI",
    "outputId": "94338e80-94f9-400b-e9cf-37e3a9fc416e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "DATA_IN_PATH = \"./data_in/\"\n",
    "data = pd.read_csv(DATA_IN_PATH + './ChatBotData.csv', encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-baWuRTXnU3N"
   },
   "source": [
    "- 결과에 응답 데이터를 보면, 주로 권유의 문자열이 많이 나오는 것을 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtrBAPWU3IGP"
   },
   "source": [
    "## 시퀀스 투 시퀀스\n",
    "- 말 그대로 시퀀스 형태의 입력값을 시퀀스 형태의 출력으로 만들 수 있게 하는 모델임 \n",
    "- 즉, 하나의 텍스트 문장이 입력으로 들어오면 하나의 텍스트 문장을 출력하는 구조임\n",
    "- 주로 사용되는 분야는 기계 번역(Machine Translation), 텍스트 요약(Text Summarization), 이미지 설명(Image Captioning), 대화 모델(Conversation Model) 등 다양한 분야에서 활용된다. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6THCgWpK39fT"
   },
   "source": [
    "### 모델의 개념\n",
    "- 우선 이 모델은 재귀 순환 신경망(RNN)모델을 기반으로 한다. \n",
    "  + RNN 모델에 대한 자세한 설명은 다음 교재에서 확인해본다. \n",
    "  + 순환 신경망: https://wikidocs.net/22886\n",
    "- 재귀 순환 신경망(RNN) 모델을 기반으로 하며, 모델은 크게 인코더(Encoder)부분과 디코더(Decoder) 부분으로 나뉜다. \n",
    "- 인코더 부분에서 입력값을 받아 입력값의 정보를 담은 벡터를 만든 이후에 디코더에서는 이 벡터를 활용해 재귀적으로 출력값을 만들어내는 구조를 가진다.\n",
    "\n",
    "![](https://jamiekang.github.io/media/2017-04-23-learning-phrase-representations-using-rnn-encoder-decoder-fig1.png)\n",
    "\n",
    "- 위 모델에 대한 한글 설명은 Jamie's Blog 게시글인 [Learning Phrase Representations Using RNN Encoder-Decoder for Statistical Machine Translation](https://jamiekang.github.io/2017/04/23/learning-phrase-representations-using-rnn-encoder-decoder/)에서 자세히 설명이 되어 있다. \n",
    "- Encoder가 input sequence x의 각 symbol을 순차적으로 읽는 것에 따라 내부의 `hidden state`가 update가 되는데, 이 때 마지막 심볼을 읽고 나면, `hidden state`는 전체 input sequence의 summary인 벡터 c가 됩니다. \n",
    "  + 이 때의 `c`는 인코더 부분의 정보를 요약해 담고 있는 벡터이고, 재귀 순환 신경망의 마지막 은식 상태 벡터값을 사용한다. \n",
    "- Decoder는 주어진 hidden state $h_{(t)}$에서 다음 symbol $y_{t}$를 생성하도록 `train`된 또 다른 `RNN`입니다. 그런데, `decoder`의 $y_{t}$와 $h_{(t)}$는 이전 symbol $y_{t-1}$ 뿐만 아니라 input sequence의 summary인 c에도 의존성이 있다. \n",
    "  + 즉, `decoder`의 `hidden state`는 아래 식과 같이 계산된다. \n",
    "  + 여기에서 $f$는 non-linear activation function을 의미한다. \n",
    "$$ h_{(t)} = f \\left ( h_{(t-1)}, y_{t-1}, c \\right ) $$\n",
    "\n",
    "- 이 두 개의 네트워크는 주어진 `source sequence`에 대해 `target sequence`가 나올 조건부 확률을 `maximize` 하도록 함께 `training`된다. 수식으로 쓰면 아래와 같이 `log-likelihood`로 표현된다. \n",
    "  + likelihood의 뜻은 데이터가 특정한 분포로부터 나올 확률을 말한다.\n",
    "$$ \\underset{\\theta }{max}=\\frac{1}{N}\\sum_{n=1}^{N}logP_{\\theta }(Y_{n}|X_{n}) $$\n",
    "\n",
    "- 여기에서 $\\theta$는 모델의 `parameter`이고, 이를 추정하기 위해 `gradient`기반의 알고리즘을 사용한다. \n",
    "- 이 모델은 두 개의 다른 언어(예: 입력-영어, 출력-프랑스어)간 번역에 사용한다. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDQROcYen7ex"
   },
   "source": [
    "## 모델 구현을 위한 사전 환경 설정\n",
    "- 먼저 모델을 구현하기 위해 `preprocess` 영역을 선 구현하도록 한다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1a8MpGItoSa2"
   },
   "source": [
    "### 구글 드라이브 연결\n",
    "- 구글 드라이브와 연결하도록 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 795,
     "status": "ok",
     "timestamp": 1608977692865,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "b2Hp9aN_obYI",
    "outputId": "8dd35f1f-f996-4df5-afc8-fe749a2fac4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/My Drive/Colab Notebooks/강림직업전문학교/프로젝트/NLP_자연어처리/ch06_챗봇_만들기/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive # 패키지 불러오기 \n",
    "from os.path import join  \n",
    "\n",
    "ROOT = \"/content/drive\"     # 드라이브 기본 경로\n",
    "print(ROOT)                 # print content of ROOT (Optional)\n",
    "drive.mount(ROOT)           # 드라이브 기본 경로 Mount\n",
    "\n",
    "MY_GOOGLE_DRIVE_PATH = 'My Drive/Colab Notebooks/강림직업전문학교/프로젝트/NLP_자연어처리/ch06_챗봇_만들기/' # 프로젝트 경로\n",
    "PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH) # 프로젝트 경로\n",
    "print(PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1648,
     "status": "ok",
     "timestamp": 1608977693732,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "yU-BofZcoejL",
    "outputId": "facc2def-f75b-457b-f7bc-a4dedb133f8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/강림직업전문학교/프로젝트/NLP_자연어처리/ch06_챗봇_만들기\n"
     ]
    }
   ],
   "source": [
    "%cd \"{PROJECT_PATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKBhT3Chopmm"
   },
   "source": [
    "### 한글 형태소 설치\n",
    "- 다음 코드로 형태소를 설치하도록 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31173,
     "status": "ok",
     "timestamp": 1608977723266,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "ktrUGCf-o4G2",
    "outputId": "bc8425f4-b9a4-4cdd-fcfe-b9494e3dbcb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
      "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
      "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [41.5 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
      "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,700 kB]\n",
      "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [870 kB]\n",
      "Fetched 2,884 kB in 2s (1,341 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
      "g++ set to manually installed.\n",
      "The following additional packages will be installed:\n",
      "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
      "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
      "  openjdk-8-jre-headless x11-utils\n",
      "Suggested packages:\n",
      "  gvfs openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin libnss-mdns\n",
      "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
      "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
      "The following NEW packages will be installed:\n",
      "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
      "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
      "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n",
      "  openjdk-8-jre openjdk-8-jre-headless x11-utils\n",
      "0 upgraded, 15 newly installed, 0 to remove and 17 not upgraded.\n",
      "Need to get 43.4 MB of archives.\n",
      "After this operation, 163 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u275-b01-0ubuntu1~18.04 [28.2 MB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u275-b01-0ubuntu1~18.04 [69.7 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u275-b01-0ubuntu1~18.04 [8,269 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u275-b01-0ubuntu1~18.04 [1,600 kB]\n",
      "Fetched 43.4 MB in 2s (23.3 MB/s)\n",
      "Selecting previously unselected package libxxf86dga1:amd64.\n",
      "(Reading database ... 145480 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
      "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../01-fonts-dejavu-core_2.37-1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.37-1) ...\n",
      "Selecting previously unselected package fonts-dejavu-extra.\n",
      "Preparing to unpack .../02-fonts-dejavu-extra_2.37-1_all.deb ...\n",
      "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
      "Selecting previously unselected package x11-utils.\n",
      "Preparing to unpack .../03-x11-utils_7.7+3build1_amd64.deb ...\n",
      "Unpacking x11-utils (7.7+3build1) ...\n",
      "Selecting previously unselected package libatk-wrapper-java.\n",
      "Preparing to unpack .../04-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
      "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
      "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
      "Preparing to unpack .../05-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
      "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
      "Selecting previously unselected package libgtk2.0-common.\n",
      "Preparing to unpack .../06-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
      "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgtk2.0-0:amd64.\n",
      "Preparing to unpack .../07-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgail18:amd64.\n",
      "Preparing to unpack .../08-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgail-common:amd64.\n",
      "Preparing to unpack .../09-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package libgtk2.0-bin.\n",
      "Preparing to unpack .../10-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
      "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
      "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
      "Preparing to unpack .../11-openjdk-8-jre-headless_8u275-b01-0ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jre-headless:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "Selecting previously unselected package openjdk-8-jre:amd64.\n",
      "Preparing to unpack .../12-openjdk-8-jre_8u275-b01-0ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jre:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
      "Preparing to unpack .../13-openjdk-8-jdk-headless_8u275-b01-0ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jdk-headless:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
      "Preparing to unpack .../14-openjdk-8-jdk_8u275-b01-0ubuntu1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jdk:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
      "Setting up fonts-dejavu-core (2.37-1) ...\n",
      "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
      "Setting up fonts-dejavu-extra (2.37-1) ...\n",
      "Setting up openjdk-8-jre-headless:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
      "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up openjdk-8-jdk-headless:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
      "Setting up x11-utils (7.7+3build1) ...\n",
      "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
      "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
      "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
      "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
      "Setting up openjdk-8-jre:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
      "Setting up openjdk-8-jdk:amd64 (8u275-b01-0ubuntu1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
      "Processing triggers for mime-support (3.60ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n",
      "Collecting konlpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
      "\u001b[K     |████████████████████████████████| 19.4MB 115kB/s \n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
      "Collecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
      "Collecting tweepy>=3.7.0\n",
      "  Downloading https://files.pythonhosted.org/packages/67/c3/6bed87f3b1e5ed2f34bd58bf7978e308c86e255193916be76e5a5ce5dfca/tweepy-3.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.4)\n",
      "Collecting beautifulsoup4==4.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 13.7MB/s \n",
      "\u001b[?25hCollecting JPype1>=0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/21/9e2c0dbf9df856e6392a1aec1d18006c60b175aa4e31d351e8278a8a63c0/JPype1-1.2.0-cp36-cp36m-manylinux2010_x86_64.whl (453kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 39.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Installing collected packages: colorama, tweepy, beautifulsoup4, JPype1, konlpy\n",
      "  Found existing installation: tweepy 3.6.0\n",
      "    Uninstalling tweepy-3.6.0:\n",
      "      Successfully uninstalled tweepy-3.6.0\n",
      "  Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "Successfully installed JPype1-1.2.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.10.0\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install g++ openjdk-8-jdk \n",
    "!pip3 install --target=$my_path konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzLLDenIpucW"
   },
   "source": [
    "### 패키지 불러오기\n",
    "- 데이터 처리를 위한 모듈을 설정한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16S6YQTdqMIr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re # 정규표현식\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd # 데이터 불러오기\n",
    "from tqdm import tqdm # Progress Bar\n",
    "\n",
    "from konlpy.tag import Okt # 한글 형태소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkdMjZVKqYDV"
   },
   "source": [
    "### 설정값 지정\n",
    "- 토큰들의 인덱스 값 지정을 하도록 한다. \n",
    "- 특별한 토큰의 의미는 아래와 같다. \n",
    "  + PAD: 어떤 의미도 없는 패딩 토큰\n",
    "  + SOS: 시작 토큰을 의미\n",
    "  + END: 종료 토큰을 의미\n",
    "  + UNK: 사전에 없는 단어를 의미\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uVrnNnLzsWyU"
   },
   "outputs": [],
   "source": [
    "FILTERS = \"([~.,!?\\\"':;)(])\" # 특수문자\n",
    "PAD = \"<PAD>\"\n",
    "STD = \"<SOS>\"\n",
    "END = \"<END>\"\n",
    "UNK = \"<UNK>\"\n",
    "\n",
    "PAD_INDEX = 0\n",
    "STD_INDEX = 1\n",
    "END_INDEX = 2\n",
    "UNK_INDEX = 3\n",
    "\n",
    "MARKER = [PAD, STD, END, UNK]\n",
    "CHANGE_FILTER = re.compile(FILTERS)\n",
    "\n",
    "MAX_SEQUENCE = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j85upI1sRn7"
   },
   "source": [
    "### 주요 함수 정의\n",
    "- 아래는 주요 함수에 대한 정의 부분이다.\n",
    "- 주석을 참고하기를 바란다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oEGT0zrwsu08"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    # 판다스를 통해서 데이터를 불러온다.\n",
    "    data_df = pd.read_csv(path, header=0)\n",
    "    # 질문과 답변 열을 가져와 question과 answer에 넣는다.\n",
    "    question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "\n",
    "    return question, answer\n",
    "\n",
    "\n",
    "def data_tokenizer(data):\n",
    "    # 토크나이징 해서 담을 배열 생성\n",
    "    words = []\n",
    "    for sentence in data:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 위 필터와 같은 값들을 정규화 표현식을\n",
    "        # 통해서 모두 \"\" 으로 변환 해주는 부분이다.\n",
    "        sentence = re.sub(CHANGE_FILTER, \"\", sentence)\n",
    "        for word in sentence.split():\n",
    "            words.append(word)\n",
    "    # 토그나이징과 정규표현식을 통해 만들어진\n",
    "    # 값들을 넘겨 준다.\n",
    "    return [word for word in words if word]\n",
    "\n",
    "\n",
    "def prepro_like_morphlized(data):\n",
    "    morph_analyzer = Okt()\n",
    "    result_data = list()\n",
    "    for seq in tqdm(data):\n",
    "        morphlized_seq = \" \".join(morph_analyzer.morphs(seq.replace(' ', '')))\n",
    "        result_data.append(morphlized_seq)\n",
    "\n",
    "    return result_data\n",
    "\n",
    "\n",
    "def load_vocabulary(path, vocab_path, tokenize_as_morph=False):\n",
    "    # 사전을 담을 배열 준비한다.\n",
    "    vocabulary_list = []\n",
    "    # 사전을 구성한 후 파일로 저장 진행한다.\n",
    "    # 그 파일의 존재 유무를 확인한다.\n",
    "    if not os.path.exists(vocab_path):\n",
    "        # 이미 생성된 사전 파일이 존재하지 않으므로\n",
    "        # 데이터를 가지고 만들어야 한다.\n",
    "        # 그래서 데이터가 존재 하면 사전을 만들기 위해서\n",
    "        # 데이터 파일의 존재 유무를 확인한다.\n",
    "        if (os.path.exists(path)):\n",
    "            # 데이터가 존재하니 판단스를 통해서\n",
    "            # 데이터를 불러오자\n",
    "            data_df = pd.read_csv(path, encoding='utf-8')\n",
    "            # 판다스의 데이터 프레임을 통해서\n",
    "            # 질문과 답에 대한 열을 가져 온다.\n",
    "            question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "            if tokenize_as_morph:  # 형태소에 따른 토크나이져 처리\n",
    "                question = prepro_like_morphlized(question)\n",
    "                answer = prepro_like_morphlized(answer)\n",
    "            data = []\n",
    "            # 질문과 답변을 extend을\n",
    "            # 통해서 구조가 없는 배열로 만든다.\n",
    "            data.extend(question)\n",
    "            data.extend(answer)\n",
    "            # 토큰나이져 처리 하는 부분이다.\n",
    "            words = data_tokenizer(data)\n",
    "            # 공통적인 단어에 대해서는 모두\n",
    "            # 필요 없으므로 한개로 만들어 주기 위해서\n",
    "            # set해주고 이것들을 리스트로 만들어 준다.\n",
    "            words = list(set(words))\n",
    "            # 데이터 없는 내용중에 MARKER를 사전에\n",
    "            # 추가 하기 위해서 아래와 같이 처리 한다.\n",
    "            # 아래는 MARKER 값이며 리스트의 첫번째 부터\n",
    "            # 순서대로 넣기 위해서 인덱스 0에 추가한다.\n",
    "            # PAD = \"<PADDING>\"\n",
    "            # STD = \"<START>\"\n",
    "            # END = \"<END>\"\n",
    "            # UNK = \"<UNKNWON>\"\n",
    "            words[:0] = MARKER\n",
    "        # 사전을 리스트로 만들었으니 이 내용을\n",
    "        # 사전 파일을 만들어 넣는다.\n",
    "        with open(vocab_path, 'w', encoding='utf-8') as vocabulary_file:\n",
    "            for word in words:\n",
    "                vocabulary_file.write(word + '\\n')\n",
    "\n",
    "    # 사전 파일이 존재하면 여기에서\n",
    "    # 그 파일을 불러서 배열에 넣어 준다.\n",
    "    with open(vocab_path, 'r', encoding='utf-8') as vocabulary_file:\n",
    "        for line in vocabulary_file:\n",
    "            vocabulary_list.append(line.strip())\n",
    "\n",
    "    # 배열에 내용을 키와 값이 있는\n",
    "    # 딕셔너리 구조로 만든다.\n",
    "    char2idx, idx2char = make_vocabulary(vocabulary_list)\n",
    "    # 두가지 형태의 키와 값이 있는 형태를 리턴한다.\n",
    "    # (예) 단어: 인덱스 , 인덱스: 단어)\n",
    "    return char2idx, idx2char, len(char2idx)\n",
    "\n",
    "def make_vocabulary(vocabulary_list):\n",
    "    # 리스트를 키가 단어이고 값이 인덱스인\n",
    "    # 딕셔너리를 만든다.\n",
    "    char2idx = {char: idx for idx, char in enumerate(vocabulary_list)}\n",
    "    # 리스트를 키가 인덱스이고 값이 단어인\n",
    "    # 딕셔너리를 만든다.\n",
    "    idx2char = {idx: char for idx, char in enumerate(vocabulary_list)}\n",
    "    # 두개의 딕셔너리를 넘겨 준다.\n",
    "\n",
    "    # 예제, [안녕, 너는, 누구야]가 데이터로 들어오면\n",
    "    # word2idx는 {'안녕':0, '너는':1, '누구야':2}가 된다. \n",
    "    # idx2word는 {0:'안녕', 1:'너는', 2:'누구야'}가 된다.\n",
    "    return char2idx, idx2char\n",
    "\n",
    "\n",
    "def enc_processing(value, dictionary, tokenize_as_morph=False):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다.)\n",
    "    sequences_input_index = []\n",
    "    # 하나의 인코딩 되는 문장의 길이를 가지고 있다.(누적된다.)\n",
    "    sequences_length = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "    if tokenize_as_morph:\n",
    "        value = prepro_like_morphlized(value)\n",
    "\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 하나의 문장을 인코딩 할때 가지고 있기 위한 배열이다.\n",
    "        sequence_index = []\n",
    "        # 문장을 스페이스 단위로 자르고 있다.\n",
    "        for word in sequence.split():\n",
    "            # 잘려진 단어들이 딕셔너리에 존재 하는지 보고\n",
    "            # 그 값을 가져와 sequence_index에 추가한다.\n",
    "            if dictionary.get(word) is not None:\n",
    "                sequence_index.extend([dictionary[word]])\n",
    "            # 잘려진 단어가 딕셔너리에 존재 하지 않는\n",
    "            # 경우 이므로 UNK(2)를 넣어 준다.\n",
    "            else:\n",
    "                sequence_index.extend([dictionary[UNK]])\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        if len(sequence_index) > MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE]\n",
    "        # 하나의 문장에 길이를 넣어주고 있다.\n",
    "        sequences_length.append(len(sequence_index))\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_input_index에 넣어 준다.\n",
    "        sequences_input_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
    "\n",
    "    # 함수 로직 요약\n",
    "    # 우선, 정규 표현식을 활용하여 특수문자 모두 제거\n",
    "    # 만약 어떤 단어가 단어 사전에 포함돼 있지 않다면 UNK 토큰을 넣는다. \n",
    "    # 인코더 최대 길이가 5라고 가정하고 다음 예시를 참조한다. \n",
    "    # 인코더 최대 길이보다 긴 경우: \"안녕 우리 너무 오랜만에 만난거 같다.\"\n",
    "    # 인코더 최대 길이보다 긴 경우 입력값: 안녕, 우리, 너무, 오랜만에, 만난거\n",
    "    # 즉, \"같다.\"가 생략된 입력값이 만들어진다. '\n",
    "    # 그런데, 인코더 최대 길이보다 짧은 경우: \"안녕\"\n",
    "    # 인코더 최대 길이보다 짧은 경우 입력값: \"안녕, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>\"\n",
    "    # 함수의 리턴값을 보면 2개의 값이 반환되는 것을 확인할 수 있다. \n",
    "    return np.asarray(sequences_input_index), sequences_length\n",
    "\n",
    "\n",
    "def dec_output_processing(value, dictionary, tokenize_as_morph=False):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다)\n",
    "    sequences_output_index = []\n",
    "    # 하나의 디코딩 입력 되는 문장의\n",
    "    # 길이를 가지고 있다.(누적된다)\n",
    "    sequences_length = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "    if tokenize_as_morph:\n",
    "        value = prepro_like_morphlized(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 하나의 문장을 디코딩 할때 가지고\n",
    "        # 있기 위한 배열이다.\n",
    "        sequence_index = []\n",
    "        # 디코딩 입력의 처음에는 START가 와야 하므로\n",
    "        # 그 값을 넣어 주고 시작한다.\n",
    "        # 문장에서 스페이스 단위별로 단어를 가져와서 딕셔너리의\n",
    "        # 값인 인덱스를 넣어 준다.\n",
    "        sequence_index = [dictionary[STD]] + [dictionary[word] if word in dictionary else dictionary[UNK] for word in sequence.split()]\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        if len(sequence_index) > MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE]\n",
    "        # 하나의 문장에 길이를 넣어주고 있다.\n",
    "        sequences_length.append(len(sequence_index))\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_output_index 넣어 준다.\n",
    "        sequences_output_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한\n",
    "    # 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_output_index), sequences_length\n",
    "\n",
    "\n",
    "def dec_target_processing(value, dictionary, tokenize_as_morph=False):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다)\n",
    "    sequences_target_index = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "    if tokenize_as_morph:\n",
    "        value = prepro_like_morphlized(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 문장에서 스페이스 단위별로 단어를 가져와서\n",
    "        # 딕셔너리의 값인 인덱스를 넣어 준다.\n",
    "        # 디코딩 출력의 마지막에 END를 넣어 준다.\n",
    "        sequence_index = [dictionary[word] if word in dictionary else dictionary[UNK] for word in sequence.split()]\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        # 그리고 END 토큰을 넣어 준다\n",
    "        if len(sequence_index) >= MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE - 1] + [dictionary[END]]\n",
    "        else:\n",
    "            sequence_index += [dictionary[END]]\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_target_index에 넣어 준다.\n",
    "        sequences_target_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_target_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWAR-yTT0Kkw"
   },
   "source": [
    "## 데이터 전처리 실전\n",
    "- 이제 데이터 처리를 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 143381,
     "status": "ok",
     "timestamp": 1608977835490,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "4KEDFxG023du",
    "outputId": "625e97d4-a854-4342-f021-222e9e0ada6b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11823/11823 [00:37<00:00, 312.78it/s]\n",
      "100%|██████████| 11823/11823 [00:36<00:00, 328.27it/s]\n",
      "100%|██████████| 11823/11823 [00:35<00:00, 333.35it/s]\n"
     ]
    }
   ],
   "source": [
    "PATH = 'data_in/ChatBotData.csv'\n",
    "VOCAB_PATH = 'data_in/vocabulary.txt'\n",
    "\n",
    "inputs, outputs = load_data(PATH)\n",
    "char2idx, idx2char, vocab_size = load_vocabulary(PATH, VOCAB_PATH, tokenize_as_morph=True)\n",
    "index_inputs, input_seq_len = enc_processing(inputs, char2idx, tokenize_as_morph=True)\n",
    "index_outputs, output_seq_len = dec_output_processing(outputs, char2idx, tokenize_as_morph=True)\n",
    "index_targets = dec_target_processing(outputs, char2idx, tokenize_as_morph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-sOCYtn3KBA"
   },
   "source": [
    "- 먼저, `load_data` 함수로 학습 데이터를 불러온다. \n",
    "- 그리고 `load_vocabulary` 함수로 단어 사전을 `char2idx`, `idx2char`로 만든다. \n",
    "- 마지막으로, `tokenize_as_morph` 파라미터를 통해 토크나이즈를 띄어쓰기 단위로 할지 형태소 단위로 할지 결정한다. \n",
    "  + 만약, `tokenize_as_morph`를 `False`로 설정하면 띄어쓰기 단위로 토크나이즈 한다. \n",
    "- 위 작업이 단어 사전을 만드는 과정으로 이해하면 된다. \n",
    "- 단어 사전까지 만들면 `enc_processing`과 `dec_output_processing`, `dec_target_processing` 함수를 통해 모델에 학습할 인덱스 데이터를 구성한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJ7h9rGJ4aL-"
   },
   "outputs": [],
   "source": [
    "data_configs = {}\n",
    "data_configs['char2idx'] = char2idx\n",
    "data_configs['idx2char'] = idx2char\n",
    "data_configs['vocab_size'] = vocab_size\n",
    "data_configs['pad_symbol'] = PAD\n",
    "data_configs['std_symbol'] = STD\n",
    "data_configs['end_symbol'] = END\n",
    "data_configs['unk_symbol'] = UNK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiavEVlI4hCS"
   },
   "source": [
    "- 인덱스 데이터를 모두 구성하고 나면 모델 학습할 때와 모델 추론에 활용하기 위해 단어 사전을 저장할 수 있도록 구성한다. \n",
    "- 여기에서는 단어 사전과 특별한 토큰들을 각각 정의해서 딕셔너리 객체에 저장하도록 한다. \n",
    "- 각 인덱스 데이터와 단어사전을 구성한 딕셔너리 객체를 `NumPy`와 `json` 형식으로 저장한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NeM_5ZTh4rlE"
   },
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "TRAIN_INPUTS = 'train_inputs.npy'\n",
    "TRAIN_OUTPUTS = 'train_outputs.npy'\n",
    "TRAIN_TARGETS = 'train_targets.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "np.save(open(DATA_IN_PATH + TRAIN_INPUTS, 'wb'), index_inputs)\n",
    "np.save(open(DATA_IN_PATH + TRAIN_OUTPUTS , 'wb'), index_outputs)\n",
    "np.save(open(DATA_IN_PATH + TRAIN_TARGETS , 'wb'), index_targets)\n",
    "\n",
    "json.dump(data_configs, open(DATA_IN_PATH + DATA_CONFIGS, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5E72ZtjH6SFW"
   },
   "source": [
    "### 결과값 확인\n",
    "- 위 코드의 결과값을 확인하도록 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 145125,
     "status": "ok",
     "timestamp": 1608977837251,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "Z87H77jT6W9q",
    "outputId": "026fd9fc-a760-41ba-f572-4de903adedcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS> is in the position 1\n",
      "<END> is in the position 2\n",
      "<UNK> is in the position 3\n",
      "들었나 is in the position 4\n",
      "보고싶으면 is in the position 5\n",
      "<PAD> is in the position 6\n"
     ]
    }
   ],
   "source": [
    "topList = ['','','','','','']\n",
    "counter = 0\n",
    "\n",
    "for char in char2idx:\n",
    "\n",
    "  # char position 확인\n",
    "  char_pos = char2idx[char]\n",
    "\n",
    "  # 인덱스 value를 저장한다. \n",
    "  if(char_pos < 10):\n",
    "    topList[char_pos-1] = char\n",
    "    counter = counter + 1\n",
    "\n",
    "  # 6이 되면 for-loop를 종료 시킨다. \n",
    "  if (counter == 6):\n",
    "    break\n",
    "\n",
    "# char top3 확인\n",
    "for n in range(0,6):\n",
    "  print(\"%s is in the position %s\" %(topList[n],n+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 145118,
     "status": "ok",
     "timestamp": 1608977837252,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "7Mx_ggwR7mxz",
    "outputId": "4da6415a-7939-47cc-cf4f-cdd8ee73556d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> is in the position 1\n",
      "<SOS> is in the position 2\n",
      "<END> is in the position 3\n",
      "<UNK> is in the position 4\n",
      "들었나 is in the position 5\n",
      "보고싶으면 is in the position 6\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for idx in idx2char:\n",
    "  counter = counter + 1\n",
    "  print(idx2char[idx], \"is in the position\", counter)\n",
    "  if (counter == 6):\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXiRs_RQ42dT"
   },
   "source": [
    "### 파일 확인\n",
    "- 실제 인덱스 데이터와 단어사전을 구성한 딕셔너리 객체가 `numpy`와 `json`형식으로 저장되었는지 확인해본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 145112,
     "status": "ok",
     "timestamp": 1608977837254,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "t5z_FkR2_Xf_",
    "outputId": "c4c4812b-9082-4028-f8ff-bb113f0e1a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBotData.csv        data_configs.json  train_inputs.npy   train_targets.npy\n",
      "ChatBotData.csv_short  NanumGothic.ttf\t  train_outputs.npy  vocabulary.txt\n"
     ]
    }
   ],
   "source": [
    "!ls \"{DATA_IN_PATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMfG7abz_f0x"
   },
   "source": [
    "## 모델 구현\n",
    "- 이제 모델을 구현하는 코드를 작성한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBGkqaBJACbe"
   },
   "source": [
    "### 모듈 불러오기\n",
    "- 딥러닝 모델 구현을 위한 모듈을 불러온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COVvoqKTAKJm"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt # 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2oMDRcleASAF"
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string], 'val_'+string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_-svWUqAoH3"
   },
   "source": [
    "### 기본 설정\n",
    "- 먼저 학습 데이터의 경로 정의한다. \n",
    "- 랜덤 시드를 고정한다.\n",
    "- 각각의 파일을 불러온다. \n",
    "- 모델 만들기에 필요한 값을 선언한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147844,
     "status": "ok",
     "timestamp": 1608977840004,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "HUCZURNDBSoP",
    "outputId": "7ed79f79-06df-4714-94ed-af2d00cb3b18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823 11823 11823\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 경로 정의\n",
    "DATA_IN_PATH = './data_in/'\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "TRAIN_INPUTS = 'train_inputs.npy'\n",
    "TRAIN_OUTPUTS = 'train_outputs.npy'\n",
    "TRAIN_TARGETS = 'train_targets.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)\n",
    "\n",
    "# 입력 파일 불러오기\n",
    "index_inputs = np.load(open(DATA_IN_PATH + TRAIN_INPUTS, 'rb'))\n",
    "index_outputs = np.load(open(DATA_IN_PATH + TRAIN_OUTPUTS , 'rb'))\n",
    "index_targets = np.load(open(DATA_IN_PATH + TRAIN_TARGETS , 'rb'))\n",
    "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))\n",
    "\n",
    "# 길이 확인하기\n",
    "print(len(index_inputs),  len(index_outputs), len(index_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsJ9WOYKBnqY"
   },
   "source": [
    "### 모델 구성하는 데 필요한 값 선언\n",
    "- 배치 크기, 에폭 횟수, 재귀 신경망의 결과 차원, 임베딩 차원, 전체 데이터셋 크기에서 평가셋의 크기 비율 등을 선언한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHKJwwduCbAR"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'seq2seq_kor'\n",
    "BATCH_SIZE = 2\n",
    "MAX_SEQUENCE = 25\n",
    "EPOCH = 30\n",
    "UNITS = 1024\n",
    "EMBEDDING_DIM = 256\n",
    "VALIDATION_SPLIT = 0.1 \n",
    "\n",
    "char2idx = prepro_configs['char2idx']\n",
    "idx2char = prepro_configs['idx2char']\n",
    "std_index = prepro_configs['std_symbol']\n",
    "end_index = prepro_configs['end_symbol']\n",
    "vocab_size = prepro_configs['vocab_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SQpb60VCci_"
   },
   "source": [
    "### 인코더 클래스 구현\n",
    "- 소스코드 설명은 주석을 참고한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvLj0CWBCm-a"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "\n",
    "    # 임베딩 룩업 테이블과 GRU를 구성하기 위한 인자를 입력으로 받는다. \n",
    "    # 배치크기, 재귀 신경망의 결과 차원(enc_units), 사전 크기(vocab_size), 임베딩 차원(embedding_dim)\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.vocab_size = vocab_size \n",
    "        self.embedding_dim = embedding_dim          \n",
    "        \n",
    "        # 사전에 포함된 각 단어를 self.embedding_dim 차원의 임베딩 벡터로 만든다. \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
    "\n",
    "        # GRU 신경망을 만드는 부분이다. \n",
    "        # self.enc_units는 GRU의 결과 차원의 크기라고 이야기할 수 있다. \n",
    "        # return_sequences는 각 시퀀스마다 출력을 반환할지 여부를 결정한다. \n",
    "        # return_state는 마지막 상태 값의 반환 여부를 의미한다. \n",
    "        # recurrent_initializer에는 초기값으로 무엇을 할 수 있는지 설정할 수 있다. \n",
    "        ## 이 때 glorot_uniform은 Xavier 초기화라고 부른다. \n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "    # 입력값 x와 은닉 상태 hidden을 받는다. \n",
    "    # __init__ 함수를 통해 `x`값을 임베딩 벡터로 만든다. \n",
    "    # gru 함수에 임베딩 벡터와 재귀 순환망의 초기화 상태로 인자로 받은 은식 상태를 전달하고, 결괏값으로 시퀀스의 출력값과 마지막 상태값을 리턴한다.\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    # 배치 크기를 받아 재귀 순환망에 초기에 사용될 크기의 은닉 상태를 만드는 역할을 함\n",
    "    def initialize_hidden_state(self, inp):\n",
    "        return tf.zeros((tf.shape(inp)[0], self.enc_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FC9PpDG4rFA4"
   },
   "source": [
    "### 어텐션 클래스 구현\n",
    "- 그런데, 기존 RNN 모델은 장기 의존성 문제가 발생할 수 있는 문제점으로 지적됐다. 따라서, 어텐션 소스코드를 추가한다.\n",
    "- 기존의 시퀀스 투 시퀀스는 인코더의 고정된 문맥 벡터가 디코더로 전달된다고 할 때, 어텐션이 추가된 방법은 은닉 상태의 값을 통해 어텐션을 계산하고 디코더의 각 시퀀스 스텝마다 계산된 어텐션을 입력으로 넣는다. \n",
    "- 즉, 어텐션도 함께 학습을 진행하게 되며 학습을 통해 디코더의 각 시퀀스 스텝마다 어텐션의 가중치는 다르게 적용된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u92_4lf9sS56"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    # 출력 벡터의 크기를 인자로 받는다. \n",
    "    # 출력 크기가 units 크기인 W1과 W2, 출력크기가 1인 V의 완전 연결 계층을 만든다.\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query는 인코더 재귀 순환망의 은닉층의 상태 값이다. \n",
    "        # values은 인코더 재귀 순환망의 결과값이다. \n",
    "        # query를 W2에 행렬곱을 할 수 있는 형태로를 만든다.\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # W1과 W2의 결괏값의 요소를 각각 더하고 하이퍼볼릭 탄젠트 활성함수를 통과한 값을 V에 행렬곱하면 1차원의 벡터값이 출력된다. \n",
    "        # 모델 훈련 중 W1, W2, V 가중치들은 학습된다. \n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        \n",
    "        # 소프트맥스 함수를 통과시켜 어텐션 가중치를 얻는데, \n",
    "        # attention_weights 값을 value, 즉 순환신경망 결괏값에 행렬 곱을 하게 되면 \n",
    "        # 1에 가까운 값에 위치한 value 값은 커지고, 0에 가까운 값에 위치한 value 값은 작아진다. \n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        # 인코더 순환 신경망의 결괏값을 어텐션 방법을 적용해 가중치를 계산해서 가중치가 적용된 새로운 인코더 순환 신경망의 결괏값을 만들어내서 디코더에 전달하게 된다. \n",
    "        # 이 때 Attention 클래스에 포함된 W1, W2, V는 학습을 통해 값들이 최적화되며, 기존 시퀀스 투 시퀀스의 문제를 해결하는 방법론이 적용된다. \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6ZqT938yq3u"
   },
   "source": [
    "### 디코더 클래스 구현\n",
    "- 이번에는 디코더 클래스를 구현하도록 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vyyf0bRy1Xv"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "\n",
    "    # Encoder 클래스와 유사하기 때문에 다른 부분만 확인한다. \n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.vocab_size = vocab_size \n",
    "        self.embedding_dim = embedding_dim  \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(self.vocab_size)\n",
    "\n",
    "        # 출력 값이 사전 크기인 완전 연결 계층 fc를 만들고 BahdanauAttention 생성한다. \n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "\n",
    "        # 디코더의 입력값 x와 인코더의 은닉 상태 값 hidden, 인코더의 결괏값을 인자로 받는다. \n",
    "        # self.attention을 호출하면 BahdanauAttention 클래스의 call 함수가 호출되고, \n",
    "        # BahdanauAttention 클래스에서 설명한 값에 따라 어텐션이 계산된 문맥 벡터(context_vector)를 돌려 받는다. \n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # 디코더의 입력값을 self.embedding 함수를 통해 임베딩 벡터를 받고 문맥 벡터와 임베딩 벡터를 결합해 x를 구성한다. \n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # 디코더 순환 신경망을 통과해서 순환 신경망의 결괏값(output)을 얻게 되고, 이 값을 완전 연결 계층(Fully-Connected Layer)을 통과한다. \n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "            \n",
    "        # 그리고, 최종적으로 사전 크기의 벡터 x를 만든다. \n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5L7F_uLq40Sz"
   },
   "source": [
    "### 손실 함수와 정확도 측정 함수\n",
    "- 딥러닝의 손실 함수 및 평가를 측정하기 위한 함수 코드를 작성한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kB6qlQI15BKi"
   },
   "outputs": [],
   "source": [
    "# 최적화로 아담을 사용한다. \n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# 크로스 엔트로피로 손실 값을 측정하기 위한 객체(loss_object)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "# 정확도 측정을 위한 객체 생성한다. \n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "# loss 함수는 인자로 정답과 예측한 값을 받아서 두 개의 값을 비교해서 손실을 계산한다. \n",
    "# real 값 중 0인 값 <PAD>는 손실 계산해서 빼기 위한 함수다.\n",
    "def loss(real, pred):\n",
    "    # 정답 real에 포함되는 값 중 0인 것은 <PAD>를 의미한다. \n",
    "    # 해당 값은 True(1)가 되고, <PAD>를 제외한 나머지 값들은 False(0)가 된다.\n",
    "    # 이 때, logical_not 함수를 적용하면 각 요소들의 값은 0에서 1로, 1에서 0으로 변경된다. \n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "\n",
    "    # 이렇게 변경된 값을 loss_ *= mask에 요소 간에 곱을 해주면 <PAD> 부분들은 loss_계산에서 빠진다. \n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
    "\n",
    "    # 정확도 측정에서 빠진다. \n",
    "    pred *= mask    \n",
    "    acc = train_accuracy(real, pred)\n",
    "\n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TucURq8J5lJ4"
   },
   "source": [
    "### seq2seq 클래스 구현\n",
    "- 각각 분리돼 있는 각각의 클래스를 이어주는 메인 클래스로 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bP7KFikZ6gvH"
   },
   "outputs": [],
   "source": [
    "class seq2seq(tf.keras.Model):\n",
    "\n",
    "    # Encoder 클래스를 생성할 때 필요한 값과 Decoder 클래스를 생성할 때 필요한 인자값을 받는다. \n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, dec_units, batch_sz, end_token_idx=2):    \n",
    "        super(seq2seq, self).__init__()\n",
    "        self.end_token_idx = end_token_idx\n",
    "        self.encoder = Encoder(vocab_size, embedding_dim, enc_units, batch_sz) \n",
    "        self.decoder = Decoder(vocab_size, embedding_dim, dec_units, batch_sz) \n",
    "\n",
    "    # 인코더의 입력값과 디코더의 입력값을 x를 통해 받는다. \n",
    "    def call(self, x):\n",
    "        inp, tar = x\n",
    "        \n",
    "        # self encoder를 통해 인코더 결괏값과 인코더 은닉 상태값을 만든다. \n",
    "        enc_hidden = self.encoder.initialize_hidden_state(inp)\n",
    "        enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        predict_tokens = list()\n",
    "        for t in range(0, tar.shape[1]):\n",
    "            dec_input = tf.dtypes.cast(tf.expand_dims(tar[:, t], 1), tf.float32) \n",
    "\n",
    "            # 디코더는 시퀀스 최대 길이만큼 반복하면서 디코더의 출력값을 만들어낸다. \n",
    "            # 또한, 시퀀스마다 나온 결괏값을 리스트(predict_tokens)에 넣어 손실 계산 또는 정확도를 계산하는 용도로 사용한다.\n",
    "            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
    "            predict_tokens.append(tf.dtypes.cast(predictions, tf.float32))   \n",
    "        return tf.stack(predict_tokens, axis=1)\n",
    "    \n",
    "    # 사용자의 입력에 대한 모델의 결괏값을 확인하기 위해 테스트 목적으로 만들어진 함수\n",
    "    # 하나의 배치만 동작하도록 돼 있ㅇ며, `<END>` 토큰을 만나면 반복문을 멈춘다. \n",
    "    def inference(self, x):\n",
    "        inp  = x\n",
    "        enc_hidden = self.encoder.initialize_hidden_state(inp)\n",
    "        enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        dec_input = tf.expand_dims([char2idx[std_index]], 1)\n",
    "        \n",
    "        predict_tokens = list()\n",
    "        for t in range(0, MAX_SEQUENCE):\n",
    "            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
    "            predict_token = tf.argmax(predictions[0])\n",
    "            \n",
    "            if predict_token == self.end_token_idx:\n",
    "                break\n",
    "            \n",
    "            predict_tokens.append(predict_token)\n",
    "            dec_input = tf.dtypes.cast(tf.expand_dims([predict_token], 0), tf.float32)   \n",
    "            \n",
    "        return tf.stack(predict_tokens, axis=0).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ah0TuAfj7y2G"
   },
   "source": [
    "## 모델 학습 및 시각화\n",
    "- 모델 학습 및 학습 결과에 대한 시각화 코드를 작성한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIX8_53D869d"
   },
   "source": [
    "### 모형 학습\n",
    "- seq2seq 객체를 생성하고, `compile` 함수를 통해 학습 방식을 설정한다. \n",
    "- 이 때의 설정은 손실 함수, 최적화 함수, 성능 측정 함수 등을 설정한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26018993,
     "status": "ok",
     "timestamp": 1609003711177,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "s0uf0Ka275Do",
    "outputId": "008df454-d896-4629-9ce0-4cd3deefb440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5320/5320 [==============================] - 942s 171ms/step - loss: 1.4983 - accuracy: 0.8118 - val_loss: 1.6116 - val_accuracy: 0.8104\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81044, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 2/30\n",
      "5320/5320 [==============================] - 895s 168ms/step - loss: 1.2172 - accuracy: 0.8122 - val_loss: 1.5745 - val_accuracy: 0.8183\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.81044 to 0.81825, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 3/30\n",
      "5320/5320 [==============================] - 861s 162ms/step - loss: 0.9905 - accuracy: 0.8203 - val_loss: 1.6296 - val_accuracy: 0.8261\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.81825 to 0.82614, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 4/30\n",
      "5320/5320 [==============================] - 851s 160ms/step - loss: 0.7412 - accuracy: 0.8285 - val_loss: 1.7327 - val_accuracy: 0.8352\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.82614 to 0.83519, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 5/30\n",
      "5320/5320 [==============================] - 853s 160ms/step - loss: 0.4799 - accuracy: 0.8383 - val_loss: 1.9187 - val_accuracy: 0.8464\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.83519 to 0.84638, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 6/30\n",
      "5320/5320 [==============================] - 851s 160ms/step - loss: 0.2761 - accuracy: 0.8498 - val_loss: 2.1004 - val_accuracy: 0.8588\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.84638 to 0.85881, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 7/30\n",
      "5320/5320 [==============================] - 847s 159ms/step - loss: 0.1562 - accuracy: 0.8620 - val_loss: 2.2472 - val_accuracy: 0.8710\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.85881 to 0.87097, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 8/30\n",
      "5320/5320 [==============================] - 852s 160ms/step - loss: 0.0897 - accuracy: 0.8738 - val_loss: 2.3842 - val_accuracy: 0.8818\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.87097 to 0.88177, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 9/30\n",
      "5320/5320 [==============================] - 853s 160ms/step - loss: 0.0586 - accuracy: 0.8841 - val_loss: 2.4937 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.88177 to 0.89103, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 10/30\n",
      "5320/5320 [==============================] - 861s 162ms/step - loss: 0.0445 - accuracy: 0.8929 - val_loss: 2.6122 - val_accuracy: 0.8988\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.89103 to 0.89884, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 11/30\n",
      "5320/5320 [==============================] - 865s 163ms/step - loss: 0.0369 - accuracy: 0.9004 - val_loss: 2.6466 - val_accuracy: 0.9054\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.89884 to 0.90544, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 12/30\n",
      "5320/5320 [==============================] - 853s 160ms/step - loss: 0.0327 - accuracy: 0.9067 - val_loss: 2.7349 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.90544 to 0.91102, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 13/30\n",
      "5320/5320 [==============================] - 852s 160ms/step - loss: 0.0272 - accuracy: 0.9121 - val_loss: 2.6963 - val_accuracy: 0.9158\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.91102 to 0.91581, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 14/30\n",
      "5320/5320 [==============================] - 867s 163ms/step - loss: 0.0238 - accuracy: 0.9167 - val_loss: 2.7820 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.91581 to 0.91996, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 15/30\n",
      "5320/5320 [==============================] - 873s 164ms/step - loss: 0.0240 - accuracy: 0.9207 - val_loss: 2.8584 - val_accuracy: 0.9236\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.91996 to 0.92358, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 16/30\n",
      "5320/5320 [==============================] - 869s 163ms/step - loss: 0.0211 - accuracy: 0.9242 - val_loss: 2.8415 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.92358 to 0.92677, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 17/30\n",
      "5320/5320 [==============================] - 857s 161ms/step - loss: 0.0204 - accuracy: 0.9273 - val_loss: 2.8791 - val_accuracy: 0.9296\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.92677 to 0.92958, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 18/30\n",
      "5320/5320 [==============================] - 870s 164ms/step - loss: 0.0196 - accuracy: 0.9301 - val_loss: 2.9809 - val_accuracy: 0.9321\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.92958 to 0.93210, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 19/30\n",
      "5320/5320 [==============================] - 872s 164ms/step - loss: 0.0191 - accuracy: 0.9325 - val_loss: 2.9613 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.93210 to 0.93437, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 20/30\n",
      "5320/5320 [==============================] - 843s 159ms/step - loss: 0.0186 - accuracy: 0.9347 - val_loss: 3.0067 - val_accuracy: 0.9364\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.93437 to 0.93641, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 21/30\n",
      "5320/5320 [==============================] - 849s 160ms/step - loss: 0.0180 - accuracy: 0.9367 - val_loss: 3.0283 - val_accuracy: 0.9383\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.93641 to 0.93826, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 22/30\n",
      "5320/5320 [==============================] - 848s 159ms/step - loss: 0.0171 - accuracy: 0.9385 - val_loss: 3.0681 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.93826 to 0.93995, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 23/30\n",
      "5320/5320 [==============================] - 849s 160ms/step - loss: 0.0173 - accuracy: 0.9402 - val_loss: 3.1004 - val_accuracy: 0.9415\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.93995 to 0.94151, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 24/30\n",
      "5320/5320 [==============================] - 853s 160ms/step - loss: 0.0165 - accuracy: 0.9417 - val_loss: 3.1339 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.94151 to 0.94292, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 25/30\n",
      "5320/5320 [==============================] - 852s 160ms/step - loss: 0.0174 - accuracy: 0.9431 - val_loss: 3.1573 - val_accuracy: 0.9442\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.94292 to 0.94422, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 26/30\n",
      "5320/5320 [==============================] - 853s 160ms/step - loss: 0.0166 - accuracy: 0.9444 - val_loss: 3.1472 - val_accuracy: 0.9454\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.94422 to 0.94542, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 27/30\n",
      "5320/5320 [==============================] - 855s 161ms/step - loss: 0.0175 - accuracy: 0.9456 - val_loss: 3.2516 - val_accuracy: 0.9465\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.94542 to 0.94654, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 28/30\n",
      "5320/5320 [==============================] - 855s 161ms/step - loss: 0.0161 - accuracy: 0.9467 - val_loss: 3.2419 - val_accuracy: 0.9476\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.94654 to 0.94757, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 29/30\n",
      "5320/5320 [==============================] - 863s 162ms/step - loss: 0.0152 - accuracy: 0.9477 - val_loss: 3.2383 - val_accuracy: 0.9485\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.94757 to 0.94854, saving model to ./data_out/seq2seq_kor/weights.h5\n",
      "Epoch 30/30\n",
      "5320/5320 [==============================] - 875s 164ms/step - loss: 0.0169 - accuracy: 0.9487 - val_loss: 3.2618 - val_accuracy: 0.9494\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.94854 to 0.94944, saving model to ./data_out/seq2seq_kor/weights.h5\n"
     ]
    }
   ],
   "source": [
    "model = seq2seq(vocab_size, EMBEDDING_DIM, UNITS, UNITS, BATCH_SIZE, char2idx[end_index])\n",
    "model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(1e-3), metrics=[accuracy])\n",
    "#model.run_eagerly = True\n",
    "\n",
    "PATH = DATA_OUT_PATH + MODEL_NAME\n",
    "if not(os.path.isdir(PATH)):\n",
    "        os.makedirs(os.path.join(PATH))\n",
    "        \n",
    "checkpoint_path = DATA_OUT_PATH + MODEL_NAME + '/weights.h5'\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=10)\n",
    "\n",
    "history = model.fit([index_inputs, index_outputs], index_targets,\n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCH,\n",
    "                    validation_split=VALIDATION_SPLIT, callbacks=[earlystop_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wf_RNS128KE2"
   },
   "source": [
    "## 모형 학습 결과 시각화 \n",
    "- 학습과 평가 정확도를 시각화한 그래프를 확인한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "executionInfo": {
     "elapsed": 26019515,
     "status": "ok",
     "timestamp": 1609003711701,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "1ywjuVfJ9WL3",
    "outputId": "c773a4cf-b540-4c33-a7d2-7d0890873a84"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Legend does not support 'accuracy' instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "executionInfo": {
     "elapsed": 26019513,
     "status": "ok",
     "timestamp": 1609003711703,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "CpN903MO9Zhj",
    "outputId": "7d09438f-6f8c-4c44-a5ee-2dfb9fae4c8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Legend does not support 'loss' instances.\n",
      "A proxy artist may be used instead.\n",
      "See: http://matplotlib.org/users/legend_guide.html#creating-artists-specifically-for-adding-to-the-legend-aka-proxy-artists\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UZwYSGjR9bIu"
   },
   "source": [
    "## 최종 테스트\n",
    "- 저장한 모델을 로드하는 방법을 본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPLZn8f39saP"
   },
   "outputs": [],
   "source": [
    "SAVE_FILE_NM = \"weights.h5\"\n",
    "model.load_weights(os.path.join(DATA_OUT_PATH, MODEL_NAME, SAVE_FILE_NM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gld1hgAs9tES"
   },
   "source": [
    "- 저장해둔 값을 불러와 사용하고 싶다면, 언제나 해당 모듈은 저장하고 불러와서 쓰는 것을 연습하도록 한다. \n",
    "- 즉, 빠르게 실습만 하고 싶다면, 아래 코드만 확인하도록 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26020028,
     "status": "ok",
     "timestamp": 1609003712222,
     "user": {
      "displayName": "Ji-hoon Jung",
      "photoUrl": "",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "4wJhiyWH-H9h",
    "outputId": "79a88471-f275-440c-f531-d801d46e6a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14356   841  6137 13442 14208   891  2718 15332  9333   200]\n",
      "진심 은 이제 로 다 생각 하 라고 말 해보세요\n"
     ]
    }
   ],
   "source": [
    "query = \"여자친구 생일 선물로 뭐가 좋을까?\"\n",
    "\n",
    "test_index_inputs, _ = enc_processing([query], char2idx)    \n",
    "predict_tokens = model.inference(test_index_inputs)\n",
    "print(predict_tokens)\n",
    "print(' '.join([idx2char[str(t)] for t in predict_tokens]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgsjX0-b-QPr"
   },
   "source": [
    "- seq2seq 모델 안에 있는 `inference` 함수를 통해 결과를 확인한다. \n",
    "- 이렇게 해서 시퀀스 투 시퀀스 기본 모델에 어텐션(Attention) 기법을 추가한 모델을 만들었다. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOjtI3ifuCUxJ4677YBM/jl",
   "collapsed_sections": [],
   "name": "step_02_seq2seq.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
